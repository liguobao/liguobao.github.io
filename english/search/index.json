[{"content":"A small project needed MySQL full DB backups. Instead of setting up replicas or cron + mysqldump, I looked for a library and found MySqlBackup.\nSnippet (from docs):\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 // Export string constring = \u0026#34;server=localhost;user=root;pwd=qwerty;database=test;\u0026#34;; string file = \u0026#34;C:\\\\backup.sql\u0026#34;; using (var conn = new MySqlConnection(constring)) using (var cmd = new MySqlCommand()) using (var mb = new MySqlBackup(cmd)) { cmd.Connection = conn; conn.Open(); mb.ExportToFile(file); } // Import using (var conn = new MySqlConnection(constring)) using (var cmd = new MySqlCommand()) using (var mb = new MySqlBackup(cmd)) { cmd.Connection = conn; conn.Open(); mb.ImportFromFile(file); } Productionized version wraps it in a service with endpoints to export/import/delete and to list backup files. It also includes a hosted service for scheduled nightly backups.\nTips:\nIf you hit connection timeouts, raise connect-timeout (e.g., 3600). For large imports: “Packets larger than max_allowed_packet…” ⇒ increase max_allowed_packet (e.g., 1GB). docker-compose example args: 1 2 3 4 5 6 args: - --lower-case-table-names=1 - --max-connections=4000 - --connect-timeout=3600 - --max-allowed-packet=1073741824 - --sql-mode=STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION Scheduled backup via IHostedService (runs daily at UTC 19:00 / Beijing 03:00):\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 public class DBBackupTimeHostedService : IHostedService, IDisposable { private readonly DBBackService _dbBackService; private Timer _timer; public DBBackupTimeHostedService(DBBackService svc) { _dbBackService = svc; } public Task StartAsync(CancellationToken ct) { _timer = new Timer(DoWork, null, GetDelayTo3AM(), TimeSpan.FromDays(1)); return Task.CompletedTask; } void DoWork(object state) { try { _dbBackService.ExportToFile(); } catch (Exception ex) { /* log */ } } public Task StopAsync(CancellationToken ct) { _timer?.Change(Timeout.Infinite, 0); return Task.CompletedTask; } public void Dispose() =\u0026gt; _timer?.Dispose(); TimeSpan GetDelayTo3AM() { var now = DateTime.UtcNow; var next = now.Date.AddHours(19); if (now.Hour \u0026gt;= 19) next = next.AddDays(1); return next - now; } } // services.AddHostedService\u0026lt;DBBackupTimeHostedService\u0026gt;(); Simple and effective — mind the risks and keep backups safe.\n","date":"2023-10-26T23:09:00Z","permalink":"https://liguobao.github.io/english/p/dotnet-core-mysql-backup/","title":"MySQL Full Backup and Restore in .NET Core"},{"content":"Python Flask Best Practices: 1) Project Initialization Preface Python Flask is a simple and convenient web framework.\nIt’s easy to build a web site or a pure Web API with it.\nI recently needed a small web + scripting project. While setting up Flask, I couldn’t find a starter that fit my taste, so I explored a bit, hit a few bumps, and then put together this tutorial on the shoulders of giants.\nProject Structure For a real project, I recommend a layered architecture (3-tier) + MVC separation to keep the code well organized. If you aren’t familiar with these concepts, it’s worth a quick read.\nNotes:\nsrc: all project source files src/service: service/business logic src/model: business entities src/db: database related, including model definitions and DAO/SQL src/sdk: external integrations/SDKs src/job: background jobs (often triggered via API) src/utils: utilities; configs live here too src/app.py: Flask app entrypoint manage.py: flask.cli entry, starts API + jobs Dockerfile: Docker build debug.py: local debug entry requirements.txt: all dependencies .vscode/launch.json: VS Code debug config Let’s Build Personal preference: I like managing dependencies via a requirements.txt. Use your preferred approach if you like.\nrequirements.txt 1 2 3 4 5 6 7 8 9 10 flask flask-swagger flask-swagger-ui flask-bootstrap SQLAlchemy pymysql pydantic requests loguru gunicorn Brief notes:\nflask is the core; flask-swagger + flask-swagger-ui provide Swagger UI; flask-bootstrap helps quickly scaffold HTML pages. SQLAlchemy + pymysql: ORM + MySQL driver. pydantic: works with SQLAlchemy for model conversion, easing serialization/deserialization quirks. requests: call external HTTP APIs or write crawlers. loguru: simple logging; from loguru import logger and you’re set. gunicorn: multi-process deployment. ","date":"2021-09-05T00:00:00Z","permalink":"https://liguobao.github.io/english/p/python-flask-1-project-initialization/","title":"Python Flask 1 Project Initialization"},{"content":"How to view Tencent Cloud’s low‑code offering? Can “everyone” become a developer? Low‑code isn’t new; Tencent Cloud is late but has its approach. A quick arc:\nFrom VMs to functions — AWS Lambda popularized FaaS; Alibaba Cloud followed; Tencent Cloud’s Serverless capabilities round out the field. Serverless improves over managed VMs/containers in ops burden and scale‑to‑zero; it changes dev patterns. Tencent’s edge is tighter ecosystem integration. What’s special about Mini‑Program Cloud Dev Built‑in cloud DB and storage are quite handy; competitors don’t ship this integrated (as far as I know). WeChat + Tencent ecosystem integrations (payments, maps, auth) make “wiring things up” faster. Tooling: VS Code extensions, WeChat DevTools, and ops integration. “Everyone is a developer”? What is software development, and what do developers do? Cloud‑dev lowers the threshold (faster iteration, quick validation), but real products still need engineering and trade‑offs. Lowering barriers helps experimentation; complexity remains for robust systems.\nFollow‑up: Does cloud‑dev lower the bar? How to assess developer value? First define the “bar”:\nWhat does it take to go from idea → online product? (requirements, data, UX, infra, security) Where do core CS concepts matter in real projects? Mini‑programs:\nCritiques: walled garden; performance limits. Pros: on‑demand usage; low entry; multi‑end unification; platform quality baseline. Mini‑program Cloud Dev:\nDeep integration with mini‑program stack Provides DB + storage capabilities Some scenarios need no/weak back‑ends or dedicated servers, lowering cost Value of developers:\nLowering the “build” bar and trial‑and‑error cost is good; turning an experiment into a stable product still needs engineering depth. “Fast, good, cheap” requires judgment — where to apply theory, where to iterate quickly, how to keep quality. ","date":"2020-11-29T00:00:00Z","permalink":"https://liguobao.github.io/english/p/qcloud-serverless-notes-on-lowcode-miniprogram-cloud-dev/","title":"QCloud Serverless — Notes on Low‑Code \u0026 Mini‑Program Cloud Dev"},{"content":"Symptoms: on startup, the first wave of traffic produced no responses while health checks looked OK, so the k8s LB kept routing, requests piled up, DB connections spiked, and pods flapped.\nWhat it wasn’t: not a DB bottleneck (CPU/IO fine), not EF per se, not external infra issues.\nContributing factors and fixes:\nWarm up DB connections and EF metadata (limited effect). Make controller/service code truly async end‑to‑end (notably improved p50/p95 and reduced startup pileups). Pre‑warm instances before cutting traffic over to reduce cold‑start jitter. Be careful with filters that do network/Redis/MaxMind work during request entry; ensure these calls are async, cached, and bounded. Root cause: a dependency injected component with expensive sync work on the hot path during startup. Fixing the DI lifetime and making the path fully async eliminated the cascade.\n","date":"2020-06-07T00:00:00Z","permalink":"https://liguobao.github.io/english/p/a-di-misstep-that-cascaded-into-startup-incidents/","title":"A DI Misstep That Cascaded into Startup Incidents"},{"content":"Repost summary of “What’s the right way to do Code Review?” — focus on clarity, empathy, and outcomes. CR is not power play; it’s a craft for improving code, systems, and teams. Review the code, not the person; discuss scenarios and trade‑offs; make each CR an opportunity to learn and teach.\n","date":"2020-04-05T00:00:00Z","permalink":"https://liguobao.github.io/english/p/the-right-posture-for-code-review-repost-english-summary/","title":"The Right Posture for Code Review (Repost — English Summary)"},{"content":"Foreword Previously we talked about Pods/Services. A Service gives you LB inside the cluster and a stable name for Pod‑to‑Pod access. But how do we expose it to the public internet?\nIn Kubernetes, Ingress handles external access (hosts, TLS, routing) — think “like nginx”, and many controllers are nginx‑based.\nOn Tencent Cloud, public IP LBs cost money (e.g., HTTP/HTTPS ALB ¥0.02/hour). If you can afford that, use the managed LB + Ingress flow in the console and click through.\nA frugal approach Your worker nodes already have public IPs. Run nginx on a node and proxy to your K8s Service’s internal IP — done.\nSo how do we give a Service an internal IP reachable from the VPC? On Tencent Cloud, annotate the Service to allocate an internal LoadBalancer IP in your subnet.\nService example:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 apiVersion: v1 kind: Service metadata: # Request an internal LB IP in your subnet annotations: service.kubernetes.io/loadbalance-id: lb-\u0026lt;your-lb-id\u0026gt; service.kubernetes.io/qcloud-loadbalancer-internal-subnetid: subnet-\u0026lt;your-subnet-id\u0026gt; name: codelover-blog namespace: default spec: externalTrafficPolicy: Cluster ports: - nodePort: 32278 port: 80 protocol: TCP targetPort: 80 selector: run: codelover-blog sessionAffinity: None type: LoadBalancer Check the result:\n1 2 3 4 5 NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) codelover-blog LoadBalancer 172.16.255.232 172.17.0.28 80:32278/TCP curl -v 172.17.0.28 ... HTTP/1.1 200 OK ... Now set up nginx on your public node:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 server { listen 80; server_name your.domain; location / { proxy_pass http://172.17.0.28:80; } error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; gzip on; gzip_min_length 5k; gzip_buffers 4 16k; gzip_http_version 1.1; gzip_comp_level 3; gzip_types text/plain application/json application/javascript text/css application/xml text/javascript image/jpeg image/gif image/png; gzip_vary on; } Done.\n","date":"2019-08-31T00:00:00Z","permalink":"https://liguobao.github.io/english/p/you-can-definitely-get-tencent-cloud-k8s-service/ingress-working/","title":"You Can Definitely Get Tencent Cloud K8s Service/Ingress Working"},{"content":"Foreword Service: .NET Core API + EF, from ~1k DAU to several tens of thousands. 6–8 Docker instances; QPS ≈ 100 overall. Per‑instance concurrency isn’t huge.\nIssue: after starting and receiving a burst of traffic, requests pile up. Logs show requests arriving but not reaching business logic or DB — they seem to await scheduling. Sometimes instances crash on start; occasionally later when a sudden surge arrives.\nKnowns:\nCrashes mostly at startup under burst; sometimes later under spikes. Instance CPU/RAM look fine; host is healthy; no heavy I/O; network is normal. Before the issue, DB connections are normal. As instances flap or hang, DB connections spike and can exhaust the pool. Guess 1: Database trouble? EF first‑use warm‑up is slow; many first‑call queries might hit DB concurrently. Tried pre‑warming DbContext pool at startup:\n1 2 3 4 5 6 7 8 9 10 11 12 13 static void InitDataContextService(IApplicationBuilder app) { Console.WriteLine($\u0026#34;Init start: {DateTime.Now}\u0026#34;); var tasks = new List\u0026lt;Task\u0026gt;(); for (var i = 0; i \u0026lt;= 10; i++) { using var scope = app.ApplicationServices.CreateScope(); var context = scope.ServiceProvider.GetRequiredService\u0026lt;XXXContext\u0026gt;(); tasks.Add(context.Database.CanConnectAsync()); } Task.WaitAll(tasks.ToArray()); Console.WriteLine($\u0026#34;Init finish: {DateTime.Now}\u0026#34;); } Effect: negligible.\nGuess 2: Sync calls block resources → pileups? Early code used synchronous controllers/services. Switched to async end‑to‑end:\n1 2 3 [HttpGet(\u0026#34;v1/books/{id}\u0026#34;, Name = \u0026#34;GetBook\u0026#34;)] public async Task\u0026lt;IActionResult\u0026gt; GetBook([FromRoute] string id) =\u0026gt; Ok(new { data = await _bookService.FindBookDetailForUser(id), code = 0 }); Result: ad‑hoc tests showed ~30–50% gains; pileups reduced.\n“Warming helps” (anecdotally) Pre‑warm instances before cutting traffic: fewer startup crashes; more stable startup. Temporary mitigation.\nRegression from a filter One iteration worsened crashes. The largest change was an ActionFilter that parsed X-Forwarded-For, looked up location in Redis, fell back to MaxMind DB, then wrote back to Redis:\n1 2 3 4 5 6 7 8 9 10 public override void OnActionExecuting(ActionExecutingContext ctx) { var dic = new Dictionary\u0026lt;string,string\u0026gt;(); string ip = ctx.HttpContext.Request.Headers.GetHeaderValue(\u0026#34;X-Forwarded-For\u0026#34;); if (ip.Contains(\u0026#39;,\u0026#39;)) ip = ip.Split(\u0026#39;,\u0026#39;)[0]; var iso = _redis.ReadHashValueByKey\u0026lt;string\u0026gt;(ConstRedisKey.IPLocations, ip) ?? _maxMind.GetIPLocationISOCode(ip).Tap(x =\u0026gt; _redis.WriteHash(ConstRedisKey.IPLocations, ip, x)); dic.Add(CommonConst.LocationHeaderKey, iso); _httpHeaderTools.CurrentXHeaders = new ThreadLocal\u0026lt;Dictionary\u0026lt;string,string\u0026gt;\u0026gt;(() =\u0026gt; dic); } This added synchronous I/O on the hot path; under cold start and bursty load, it exacerbated pileups.\nTakeaways Make the entire request path truly async; avoid sync I/O and heavy work in filters/middleware. Pre‑warm critical pools/metadata to reduce cold‑start jitter. Measure under realistic burst/cold‑start scenarios. ","date":"2019-08-03T00:00:00Z","permalink":"https://liguobao.github.io/english/p/.net-core-async-tuning-a-tale-of-cold-starts-and-pileups/","title":".NET Core “Async Tuning” — A Tale of Cold Starts and Pileups"},{"content":"Swagger for ASP.NET Core Web API Swagger/OpenAPI has become the de facto way to document REST APIs. Instead of maintaining a YAML/JSON manually, let Swashbuckle generate docs from your controllers.\nGetting Started Microsoft tutorial: https://docs.microsoft.com/aspnet/core/tutorials/getting-started-with-swashbuckle Repo: https://github.com/domaindrivendev/Swashbuckle.AspNetCore Install packages:\n1 2 dotnet add package Swashbuckle.AspNetCore --version 4.0.1 dotnet add package Swashbuckle.AspNetCore.Annotations --version 4.0.1 Startup configuration:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 public void ConfigureServices(IServiceCollection services) { services.AddMvc().SetCompatibilityVersion(CompatibilityVersion.Version_2_2); services.AddSwaggerGen(c =\u0026gt; { c.SwaggerDoc(\u0026#34;v1\u0026#34;, new Info { Title = \u0026#34;XX-404 API\u0026#34;, Version = \u0026#34;v1\u0026#34; }); c.EnableAnnotations(); }); } public void Configure(IApplicationBuilder app, IHostingEnvironment env) { app.UseSwagger(); app.UseSwaggerUI(c =\u0026gt; { c.RoutePrefix = \u0026#34;docs\u0026#34;; c.SwaggerEndpoint(\u0026#34;/swagger/v1/swagger.json\u0026#34;, \u0026#34;Zhihu-404 API\u0026#34;); }); app.UseMvc(); } Example controllers (abbrev.):\n1 2 3 4 5 6 7 [Route(\u0026#34;api/v1/health\u0026#34;)] [ApiController] public class HealthController : ControllerBase { [HttpGet] public ActionResult\u0026lt;IEnumerable\u0026lt;string\u0026gt;\u0026gt; Get() =\u0026gt; new [] { \u0026#34;value1\u0026#34;, \u0026#34;value2\u0026#34; }; } 1 2 3 4 5 6 7 8 9 10 11 12 13 [ApiController] public class ExtendDataController : ControllerBase { [HttpPost(\u0026#34;api/v1/extend-data\u0026#34;)] [SwaggerResponse(200, \u0026#34;\u0026#34;, typeof(int))] public ActionResult AddExtendData([FromBody, SwaggerParameter(\u0026#34;raw data\u0026#34;)] List\u0026lt;DBExtendData\u0026gt; extendData) { if (extendData == null || extendData.Any(a =\u0026gt; a.Id == default)) throw new Exception(\u0026#34;Invalid input; check each Id\u0026#34;); var count = 10; // bulk insert return Ok(new { code = 0, data = count }); } } Open http://localhost:5000/docs to view the generated UI.\n","date":"2019-07-06T00:00:00Z","permalink":"https://liguobao.github.io/english/p/.net-core-web-api-generate-swagger-docs-with-swashbuckle/","title":".NET Core Web API — Generate Swagger Docs with Swashbuckle"},{"content":"Kubernetes on Tencent Cloud: From Zero to Running Intro Tencent Cloud’s managed k8s had been around for a while and supports joining your own hosts. Time to experiment.\nWhat is k8s (quickly)? Kubernetes is an open-source system for automating deployment, scaling, and management of containerized apps. It groups containers into logical units for easy management and discovery.\nPlainly: we containerized our services already; k8s orchestrates and manages those containers.\nStep 1: Create a Cluster In your cloud console, find “Container Service”, create a managed cluster, click through the wizard. Join your existing or new instances as worker nodes. Two node types:\nmaster: runs k8s control-plane (etcd, etc.) worker: runs your workloads (Pods) Managed clusters hide master ops; you manage/join your workers.\nStep 2: kubectl Install kubectl and connect to the cluster (see your cloud docs). Verify:\n1 kubectl version Concepts: Pod and Service Pod: one or more container instances of an app. Service: stable, virtual IP/endpoint inside the cluster that load-balances to Pod replicas. Example: A scalable web API runs 3 replicas in one Deployment/Pod template; a Service exposes a single endpoint that forwards to replicas.\nFirst Deployment \u0026amp; Service Save as sample.yaml, then run kubectl apply -f sample.yaml.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 --- apiVersion: extensions/v1beta1 kind: Deployment metadata: labels: run: first-web-size name: first-web-size spec: replicas: 2 selector: matchLabels: run: first-web-size strategy: rollingUpdate: maxSurge: 1 maxUnavailable: 1 type: RollingUpdate template: metadata: labels: run: first-web-size spec: containers: - image: mcr.microsoft.com/dotnet/core/samples:aspnetapp imagePullPolicy: IfNotPresent name: first-web-size livenessProbe: httpGet: path: /v1/health port: 80 initialDelaySeconds: 120 periodSeconds: 30 resources: limits: cpu: 500m memory: 512Mi requests: cpu: 50m memory: 128Mi dnsPolicy: ClusterFirst restartPolicy: Always terminationGracePeriodSeconds: 30 --- apiVersion: v1 kind: Service metadata: name: first-web-size annotations: service.kubernetes.io/qcloud-loadbalancer-internal-subnetid: subnet-xxx spec: selector: run: first-web-size ports: - protocol: TCP port: 80 targetPort: 80 type: LoadBalancer externalTrafficPolicy: Cluster Apply and check:\n1 2 3 kubectl apply -f sample.yaml kubectl get pods kubectl get service first-web-size From a host on the same VPC:\n1 curl http://\u0026lt;CLUSTER-IP\u0026gt; Cleanup:\n1 kubectl delete -f sample.yaml ","date":"2019-06-09T00:00:00Z","permalink":"https://liguobao.github.io/english/p/k8s-from-first-steps-to-cleanup-on-tencent-cloud/","title":"K8s From First Steps to Cleanup on Tencent Cloud"},{"content":"macOS Installing pycrypto — Clang ‘stdio.h’ Not Found While installing a Python package that builds a C extension with Clang, I kept seeing:\n1 2 3 4 5 6 clang-4.0: warning: argument unused during compilation: \u0026#39;-L/usr/local/lib\u0026#39; [-Wunused-command-line-argument] src/_fastmath.c:29:10: fatal error: \u0026#39;stdio.h\u0026#39; file not found #include \u0026lt;stdio.h\u0026gt; ^~~~~~~~~ 1 error generated. error: command \u0026#39;clang\u0026#39; failed with exit status 1 Checked Clang:\n1 2 3 4 clang --version clang version 4.0.1 (tags/RELEASE_401/final) Target: x86_64-apple-darwin18.5.0 InstalledDir: /usr/local/opt/llvm@4/bin Looks fine… Tried setting env:\n1 export \u0026#34;CFLAGS=-I/usr/local/include -L/usr/local/lib\u0026#34; No luck. From Stack Overflow, the fix was to install SDK headers:\n1 2 3 cd /Library/Developer/CommandLineTools/Packages open macOS_SDK_headers_for_macOS_xx.pgk # choose the pkg matching your macOS version Run the installer UI, proceed… It works. Then pip install pycrypto succeeds.\n","date":"2019-05-09T00:00:00Z","permalink":"https://liguobao.github.io/english/p/macos-installing-pycrypto-clang-stdio.h-not-found/","title":"macOS Installing pycrypto — Clang ‘stdio.h’ Not Found"},{"content":"Server-Side Caching for APIs with an Action Filter Instead of sprinkling cache lookups/writes across controllers, add a reusable ActionFilter that caches responses in Redis based on the request path + querystring.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 public class DefaultCacheFilterAttribute : ActionFilterAttribute { protected TimeSpan _expireTime; // override in subclass for custom TTLs private readonly RedisService _redisService; public DefaultCacheFilterAttribute(RedisService redisService) =\u0026gt; _redisService = redisService; public override void OnActionExecuting(ActionExecutingContext context) { if (context.HttpContext.Request.Query.ContainsKey(\u0026#34;refresh\u0026#34;)) return; var redisKey = GetRequestRedisKey(context.HttpContext); var cached = _redisService.ReadCache\u0026lt;JToken\u0026gt;(redisKey); if (cached != null) context.Result = new ObjectResult(cached); } public override void OnActionExecuted(ActionExecutedContext context) { var obj = (ObjectResult)context.Result; if (obj == null) return; var key = GetRequestRedisKey(context.HttpContext); _redisService.WriteCache(key, JToken.FromObject(obj.Value)); } private KeyConfig GetRequestRedisKey(HttpContext http) { var path = http.Request.Path.Value; if (!string.IsNullOrEmpty(http.Request.QueryString.Value)) path += http.Request.QueryString.Value; if (http.Request.Query.ContainsKey(\u0026#34;refresh\u0026#34;)) path = path.Replace(\u0026#34;?refresh=true\u0026#34;, \u0026#34;\u0026#34;).Replace(\u0026#34;refresh=true\u0026#34;, \u0026#34;\u0026#34;); var key = ConstRedisKey.HTTPRequest.CopyOne(path); if (_expireTime != default) key.ExpireTime = _expireTime; return key; } } public static class ConstRedisKey { public static readonly KeyConfig HTTPRequest = new KeyConfig { Key = \u0026#34;lemon_req_\u0026#34;, ExpireTime = TimeSpan.FromMinutes(30), DBName = 5 }; } Usage:\n1 2 3 4 [HttpGet(\u0026#34;v1/xxx/latest\u0026#34;)] [ServiceFilter(typeof(DefaultCacheFilterAttribute))] public IActionResult GetLatestList([FromQuery] int page = 0, [FromQuery] int pageSize = 30) =\u0026gt; Ok(new { data = _service.LoadLatest(page, pageSize), code = 0 }); Register DefaultCacheFilterAttribute in DI (Startup). Optionally subclass to set different TTLs per action.\n","date":"2019-05-05T00:00:00Z","permalink":"https://liguobao.github.io/english/p/asp.net-core-add-server-side-cache-via-action-filter/","title":"ASP.NET Core — Add Server-Side Cache via Action Filter"},{"content":"Test Coverage with coverlet + ReportGenerator Need coverage for .NET Core? Use coverlet to collect, and ReportGenerator to render HTML.\ncoverlet Install either as a global tool or as an MSBuild package:\n1 dotnet tool install --global coverlet.console or add to your test project:\n1 \u0026lt;PackageReference Include=\u0026#34;coverlet.msbuild\u0026#34; Version=\u0026#34;2.5.0\u0026#34; /\u0026gt; Then run tests with coverage:\n1 2 3 4 dotnet test \\ /p:CollectCoverage=true \\ /p:CoverletOutput=\u0026#39;./results/\u0026#39; \\ /p:CoverletOutputFormat=opencover Outputs coverage.opencover.xml under results/.\nReportGenerator Render human‑readable reports from XML:\n1 2 dotnet tool install --global dotnet-reportgenerator-globaltool reportgenerator \u0026#39;-reports:UnitTests/results/*.xml\u0026#39; \u0026#39;-targetdir:UnitTests/results\u0026#39; Open UnitTests/results/index.htm to view the coverage report.\n","date":"2019-04-08T00:00:00Z","permalink":"https://liguobao.github.io/english/p/.net-core-unit-test-coverage-with-coverlet--reportgenerator/","title":".NET Core Unit Test Coverage with coverlet + ReportGenerator"},{"content":"Adopt the 202 Accepted + polling pattern; implement with Redis Sorted Sets + pub/sub and a background worker to process tasks. Details mirror the Chinese post.\n","date":"2019-04-05T00:00:00Z","permalink":"https://liguobao.github.io/english/p/task-queue-and-async-api-pattern-in-.net-core/","title":"Task Queue and Async API Pattern in .NET Core"},{"content":"Ops Tale: The Day rm -rf /* Took My Box The Trigger Users reported mobile web showing a blank page. On desktop: same — HTML loads, but a core JS fails. Error: “We’re sorry but house doesn’t work properly without JavaScript enabled…”. Another network error: ERR_INCOMPLETE_CHUNKED_ENCODING.\nTried the usual:\nRestart the Docker container — no luck Roll back build — no luck Restart nginx — no luck Nginx logs — nothing helpful Lightbulb: maybe disk full. df -h: 99.99% used. One Docker container using 34G — probably Elasticsearch. Killed it, cleared data, restarted nginx — back to normal. Problem solved… for now.\nBut ES needs to come back. Let’s attach and mount a separate data disk.\nThe Mistake Followed the cloud console to attach a disk, partitioned, and attempted to mount. Saw a warning, tried another device, mounted again, then “clean up the disk” — and ran:\n1 rm -rf ./* Suddenly some files were “busy”, then ls vanished, cat vanished, cp failed… only cd still worked. Yep — I had mounted the system disk path and wiped it.\nPostmortem Didn’t format before mounting; first mount failed Didn’t check why; tried another mount blindly Mounted the system disk path and deleted blindly rm -rf ./* — game over Recovery Attempt Services still running via Docker; images kept in registry, so recoverable. But configs/certs lived on the host. With most tools gone, not much to read. A teammate suggested checking for snapshots — I had a system image from two weeks earlier.\nRestored from image, updated service images — back online.\nTakeaways Separate data and system disks; don’t let app data kill the OS Enable snapshot policy if budget allows; at worst you roll back a week Before destructive ops, create a system image — a literal lifesaver ","date":"2018-11-20T00:00:00Z","permalink":"https://liguobao.github.io/english/p/ops-tale-the-day-rm-rf-/-took-my-box/","title":"Ops Tale The Day rm -rf /* Took My Box"},{"content":"Site moved to a new address New domain: https://house2048.cn/app/house-map/#/ New version link Click here: https://house2048.cn/app/house-map A WeChat Mini Program is online. Follow the “人生删除指南” official account to get it. Project repo: https://github.com/liguobao/58HouseSearch Latest user guide Guide (Chinese): https://github.com/liguobao/58HouseSearch/blob/master/%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B.md\nFor the latest address, see the guide ","date":"2018-09-04T00:00:00Z","permalink":"https://liguobao.github.io/english/p/house-search-map-project-migration-house2048.cn/","title":"House Search Map Project Migration (house2048.cn)"},{"content":"Hydra is an OpenID Connect certified OAuth2 server. The post walks through running it with Docker and Postgres/MySQL.\n","date":"2018-07-28T00:00:00Z","permalink":"https://liguobao.github.io/english/p/weekly-open-source-hydra-oauth2/openid-connect-server/","title":"Weekly Open Source — Hydra (OAuth2/OpenID Connect Server)"},{"content":"APM and distributed tracing with SkyWalking; installation links and quick tips.\n","date":"2018-07-15T00:00:00Z","permalink":"https://liguobao.github.io/english/p/weekly-open-source-apache-skywalking/","title":"Weekly Open Source — Apache SkyWalking"},{"content":"Featuring a timed job library for .NET Core and examples of scheduled tasks.\n","date":"2018-07-01T00:00:00Z","permalink":"https://liguobao.github.io/english/p/weekly-open-source-timed-jobs-in-.net-core/","title":"Weekly Open Source — Timed Jobs in .NET Core"},{"content":"Backend API Starter Guide Key concepts and references for building RESTful APIs in common stacks.\nRESTful API Understand HTTP and REST design References: Ruanyifeng: Understanding RESTful Architecture Ruanyifeng: RESTful API Design Guide RESTful API resources collection Dependency Injection (DI) Intro to DI and software architecture patterns Java JDK 1.8+ IDE: IntelliJ IDEA DB: MySQL 5.7+, cache: Redis Data layer: MyBatis (or JPA), build: Maven/Gradle Framework: Spring Boot + Spring MVC Goal: build CRUD Web APIs with Spring Boot C# (.NET) .NET: .NET Core 2.x IDE: VS Code + SDK (or Visual Studio) DB: MySQL 5.7+, cache: Redis Data layer: Dapper Framework: ASP.NET Core MVC with built‑in DI Goal: build CRUD Web APIs with ASP.NET Core Python Python 3.6+ IDE: VS Code (+ Python extension) or PyCharm DB: MySQL 5.7+, cache: Redis ORM: SQLAlchemy Framework: Flask Goal: build CRUD Web APIs with Flask PHP PHP 7.1+ IDE: VS Code (+ PHP Debug) + nginx + php‑fpm DB: MySQL 5.7+, cache: Redis Framework: Laravel; build: Composer Goal: build CRUD Web APIs with Laravel Node.js Node.js 9+ IDE: VS Code DB: MySQL 5.7+, cache: Redis ORM: Sequelize (or orm2) Build: npm Framework: Express Goal: build CRUD Web APIs with Express ","date":"2018-06-18T00:00:00Z","permalink":"https://liguobao.github.io/english/p/backend-api-starter-guide/","title":"Backend API Starter Guide"},{"content":"Overview of configuration providers, options pattern, environment‑specific json, and injecting typed options.\n","date":"2018-05-31T00:00:00Z","permalink":"https://liguobao.github.io/english/p/.net-core-configuration-appsettings-environments-di/","title":".NET Core Configuration — AppSettings, Environments, DI"},{"content":"Follow‑up to Part 1: scaffolding a web app, controllers/views/routes, DI, and configuration basics.\n","date":"2018-05-30T00:00:00Z","permalink":"https://liguobao.github.io/english/p/.net-core-mvc-getting-started-part-2/","title":".NET Core MVC — Getting Started (Part 2)"},{"content":".NET Core (Getting Started) Environment Install the .NET SDK: https://www.microsoft.com/net/learn/get-started\nWindows: Visual Studio 2017 (select .NET Core workload) macOS/Linux: SDK + VS Code (+ C# extension) Verify:\n1 2 dotnet --version dotnet help Create a project List templates: dotnet new\nCreate and run a console app:\n1 2 3 dotnet new console -n FirstApplication cd FirstApplication dotnet run Open in VS Code, install the C# extension, and debug (set breakpoints, F5/F10/F11).\nExample loop:\n1 2 3 4 5 for (var i = 0; i \u0026lt; 10; i++) { sum += i; Console.WriteLine($\u0026#34;i:{i}, sum:{sum}\u0026#34;); } About .csproj Console:\n1 2 3 4 5 6 \u0026lt;Project Sdk=\u0026#34;Microsoft.NET.Sdk\u0026#34;\u0026gt; \u0026lt;PropertyGroup\u0026gt; \u0026lt;OutputType\u0026gt;Exe\u0026lt;/OutputType\u0026gt; \u0026lt;TargetFramework\u0026gt;netcoreapp2.0\u0026lt;/TargetFramework\u0026gt; \u0026lt;/PropertyGroup\u0026gt; \u0026lt;/Project\u0026gt; Web projects use Microsoft.NET.Sdk.Web and PackageReference entries for dependencies (e.g., ASP.NET Core, Dapper, Newtonsoft.Json). More details in the next part.\n","date":"2018-05-29T00:00:00Z","permalink":"https://liguobao.github.io/english/p/.net-core-hands-on-part-1-getting-started/","title":".NET Core Hands-on (Part 1 Getting Started)"},{"content":"Quickstart: use the AMap JS API (Autocomplete, ArrivalRange, Transfer) on the front end and Python 3 on the back end to serve listings. The HTML and scripts from the Chinese post are unchanged.\n","date":"2018-05-23T00:00:00Z","permalink":"https://liguobao.github.io/english/p/build-a-simple-rental-map-in-30-minutes-python--amap/","title":"Build a Simple Rental Map in 30 Minutes (Python + AMap)"},{"content":"Debugging PHP on macOS with VS Code (xdebug) Windows guide: https://zhuanlan.zhihu.com/p/25844268\nHomebrew Install brew from https://brew.sh or:\n1 /usr/bin/ruby -e \u0026#34;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\u0026#34; PHP7 + nginx + php-fpm + xdebug PHP 7 1 2 3 4 brew install php@7.1 where php # /usr/local/opt/php@7.1/bin/php # /usr/bin/php php.ini is typically under /usr/local/etc/php/7.1 (we’ll need it later).\nInstall xdebug Homebrew’s php71-xdebug was removed. Build manually. Download from https://xdebug.org/files/ and compile:\n1 2 3 4 5 6 7 8 mkdir ~/tool \u0026amp;\u0026amp; cd ~/tool wget https://xdebug.org/files/xdebug-2.6.0.tgz tar xvzf xdebug-2.6.0.tgz cd xdebug-2.6.0 phpize ./configure --enable-xdebug --with-php-config=/usr/local/Cellar/php@7.1/7.1.17/bin/php-config make \u0026amp;\u0026amp; make test # xdebug-2.6.0/modules/xdebug.so will be generated Install nginx 1 brew install nginx nginx.conf Create directories and a minimal config:\n1 2 3 mkdir -p /usr/local/var/logs/nginx mkdir -p /usr/local/etc/nginx/{sites-available,sites-enabled,conf.d,ssl} sudo mkdir -p /var/www \u0026amp;\u0026amp; sudo chown :staff /var/www \u0026amp;\u0026amp; sudo chmod 777 /var/www /usr/local/etc/nginx/nginx.conf:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 user root wheel; worker_processes 1; error_log /usr/local/var/logs/nginx/error.log debug; pid /usr/local/var/run/nginx.pid; events { worker_connections 256; } http { include mime.types; default_type application/octet-stream; log_format main \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; access_log /usr/local/var/logs/access.log main; sendfile on; keepalive_timeout 65; port_in_redirect off; include /usr/local/etc/nginx/sites-enabled/*; } /usr/local/etc/nginx/conf.d/php-fpm:\n1 2 3 4 5 6 7 location ~ \\.php$ { try_files $uri =404; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_intercept_errors on; include /usr/local/etc/nginx/fastcgi.conf; } Site file /usr/local/etc/nginx/sites-available/default:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 server { listen 80; server_name example.local; root /var/www/pet/public; access_log /usr/local/var/logs/nginx/default.access.log main; index index.php index.html index.htm; location / { try_files $uri $uri/ /index.php?$query_string; } location ~ \\.php$ { fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; } } Enable the site by symlinking into sites-enabled, configure php-fpm and xdebug in php.ini, and set up VS Code’s PHP debug extension.\n","date":"2018-05-21T00:00:00Z","permalink":"https://liguobao.github.io/english/p/debugging-php-on-macos-with-vs-code-xdebug/","title":"Debugging PHP on macOS with VS Code (xdebug)"},{"content":"logstash grok Configuration Patterns logstash.conf Configure grok { match =\u0026gt; ... } to split logs into indexed fields (matches are essentially regex patterns).\nRaw log:\n1 2018-04-13 16:03:49.822 INFO o.n.p.j.c.XXXXX - Star Calculator grok match:\n1 match =\u0026gt; { \u0026#34;message\u0026#34; =\u0026gt; \u0026#34;%{DATA:log_date} %{TIME:log_localtime} %{WORD:log_type} %{JAVAFILE:log_file} - %{GREEDYDATA:log_content}\u0026#34;} Parsed fields:\n1 2 3 4 5 6 7 8 9 10 { \u0026#34;log_date\u0026#34;: [[\u0026#34;2018-04-13\u0026#34;]], \u0026#34;log_localtime\u0026#34;: [[\u0026#34;16:03:49.822\u0026#34;]], \u0026#34;HOUR\u0026#34;: [[\u0026#34;16\u0026#34;]], \u0026#34;MINUTE\u0026#34;: [[\u0026#34;03\u0026#34;]], \u0026#34;SECOND\u0026#34;: [[\u0026#34;49.822\u0026#34;]], \u0026#34;log_type\u0026#34;: [[\u0026#34;INFO\u0026#34;]], \u0026#34;log_file\u0026#34;: [[\u0026#34;o.n.p.j.c.XXXX\u0026#34;]], \u0026#34;log_content\u0026#34;: [[\u0026#34;Star Calculator\u0026#34;]] } All extracted fields are ES mapping indices and can be queried.\nTest patterns at: http://grokdebug.herokuapp.com/ and view available patterns at http://grokdebug.herokuapp.com/patterns\nWe use a config like /logstash/logstash-k8s.conf.\nQ: How to force data types in mapping? A: grok is regex-based; defaults are strings. You can cast numeric fields inline, e.g. %{NUMBER:response_time:int}.\nFull example:\n1 2 3 match =\u0026gt; { \u0026#34;message\u0026#34; =\u0026gt; \u0026#34;%{DATA:log_date} %{TIME:log_localtime} %{WORD:log_type} %{JAVAFILE:log_file} - %{WORD:method} %{URIPATHPARAM:uri} %{NUMBER:status:int} %{NUMBER:size:int} %{NUMBER:response_time:int}\u0026#34; } Q: Store indices by date? A: In output, set index format, e.g. index =\u0026gt; \u0026quot;k8s-%{+YYYY.MM.dd}\u0026quot;.\nFull output:\n1 2 3 4 5 6 7 output { elasticsearch { hosts =\u0026gt; \u0026#34;${ES_URL}\u0026#34; manage_template =\u0026gt; false index =\u0026gt; \u0026#34;k8s-%{+YYYY.MM.dd}\u0026#34; } } Full logstash.conf:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 input { beats { host =\u0026gt; \u0026#34;0.0.0.0\u0026#34; port =\u0026gt; 5043 } } filter { if [type] == \u0026#34;kube-logs\u0026#34; { mutate { rename =\u0026gt; [\u0026#34;log\u0026#34;, \u0026#34;message\u0026#34;] } date { match =\u0026gt; [\u0026#34;time\u0026#34;, \u0026#34;ISO8601\u0026#34;] remove_field =\u0026gt; [\u0026#34;time\u0026#34;] } grok { match =\u0026gt; { \u0026#34;source\u0026#34; =\u0026gt; \u0026#34;/var/log/containers/%{DATA:pod_name}_%{DATA:namespace}_%{GREEDYDATA:container_name}-%{DATA:container_id}.log\u0026#34; } match =\u0026gt; { \u0026#34;message\u0026#34; =\u0026gt; \u0026#34;%{DATA:log_date} %{TIME:log_localtime} %{WORD:log_type} %{JAVAFILE:log_file} - %{WORD:method} %{URIPATHPARAM:uri} %{NUMBER:status:int} %{NUMBER:size:int} %{NUMBER:response_time:int}\u0026#34; } remove_field =\u0026gt; [\u0026#34;source\u0026#34;] break_on_match =\u0026gt; false } } } output { elasticsearch { hosts =\u0026gt; \u0026#34;${ES_URL}\u0026#34; manage_template =\u0026gt; false index =\u0026gt; \u0026#34;k8s-%{+YYYY.MM.dd}\u0026#34; } } ","date":"2018-05-20T00:00:00Z","permalink":"https://liguobao.github.io/english/p/logstash-grok-configuration-patterns/","title":"logstash grok Configuration Patterns"},{"content":"Hexo Install and scaffold:\n1 2 3 4 5 npm install hexo-cli -g hexo init blog cd blog npm install hexo server Docs: https://hexo.io\nDocker Deployment Dockerfile:\n1 2 3 4 5 6 7 8 9 10 11 12 13 FROM node:latest AS build-env RUN mkdir -p /usr/src/hexo-blog WORKDIR /usr/src/hexo-blog COPY . . RUN npm --registry=https://registry.npm.taobao.org install hexo-cli -g \u0026amp;\u0026amp; npm install RUN hexo clean \u0026amp;\u0026amp; hexo g FROM nginx:latest ENV TZ=Asia/Shanghai RUN ln -snf /usr/share/zoneinfo/$TZ /etc/localtime \u0026amp;\u0026amp; echo $TZ \u0026gt; /etc/timezone WORKDIR /usr/share/nginx/html COPY --from=build-env /usr/src/hexo-blog/public /usr/share/nginx/html EXPOSE 80 Build and run:\n1 2 docker build -t hexo-blog:latest . docker run -p 80:80 -d hexo-blog:latest Nginx TLS Config Obtain a cert (e.g., via https://freessl.org/), then use an nginx.conf like:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 events { worker_connections 1024; } http { server { listen 443; server_name example.com; root /usr/share/nginx/html; index index.html index.htm; ssl on; ssl_certificate /etc/nginx/full_chain.pem; ssl_certificate_key /etc/nginx/private.key; include /etc/nginx/mime.types; gzip on; gzip_min_length 5k; gzip_buffers 4 16k; gzip_http_version 1.1; gzip_comp_level 3; gzip_types text/plain application/json application/javascript text/css application/xml text/javascript image/jpeg image/gif image/png; gzip_vary on; } server { listen 80; server_name example.com; root /usr/share/nginx/html; index index.html index.htm; include /etc/nginx/mime.types; } } Run with mounts for config and certs:\n1 2 3 4 5 6 docker run -p 80:80 -p 443:443 \\ --name hexo-site \\ -v ~/docker-data/site/nginx.conf:/etc/nginx/nginx.conf \\ -v ~/docker-data/site/ssl/full_chain.pem:/etc/nginx/full_chain.pem \\ -v ~/docker-data/site/ssl/private.key:/etc/nginx/private.key \\ --restart=always -d hexo-blog:latest Example reverse-proxy config (non-static): define upstreams and proxy_pass in server blocks as needed.\n","date":"2018-05-18T00:00:00Z","permalink":"https://liguobao.github.io/english/p/build-and-deploy-a-hexo-blog-with-docker/","title":"Build and Deploy a Hexo Blog with Docker"},{"content":"Install JDK 8, then run Jenkins from the war:\n1 2 3 4 5 6 7 8 sudo add-apt-repository ppa:webupd8team/java sudo apt-get update sudo apt-get install oracle-java8-installer wget http://mirrors.jenkins.io/war-stable/2.107.2/jenkins.war mkdir ~/jenkins-home \u0026amp;\u0026amp; export JENKINS_HOME=~/jenkins-home tmux java -jar jenkins.war Open port 8080, use the initial admin password from .../secrets/initialAdminPassword, install suggested plugins, create admin.\nWe’ll return to Jenkins after preparing Docker builds for our .NET Core app.\nDockerfile for .NET Core In your project folder, Dockerfile:\n1 2 3 4 5 6 7 8 9 10 11 FROM microsoft/aspnetcore-build:2.0 AS build-env WORKDIR /app COPY *.csproj ./ RUN dotnet restore COPY . ./ RUN dotnet publish -c Release -o out FROM microsoft/aspnetcore:2.0 WORKDIR /app COPY --from=build-env /app/out . ENTRYPOINT [\u0026#34;dotnet\u0026#34;, \u0026#34;YourApp.dll\u0026#34;] Optional local build/run script 1 2 3 4 5 6 7 image_version=$(date +%Y%m%d%H%M) docker stop house-web || true \u0026amp;\u0026amp; docker rm house-web || true docker build -t house-web:$image_version . docker run -p 8080:80 \\ -v ~/docker-data/house-web/appsettings.json:/app/appsettings.json \\ -v ~/docker-data/house-web/NLogFile/:/app/NLogFile \\ --restart=always --name house-web -d house-web:$image_version Jenkins Job New item → Freestyle project Source Code Management → Git (configure credentials/keys as needed) Build → “Execute shell” with either the local build script above, or a remote ssh user@host '~/start_XXX.sh'. Better builds with Aliyun Container Registry (ACR) Instead of building on Jenkins/host, connect your repo to Aliyun Container Registry (ACR) and enable “auto build on code changes”. ACR will build and host your images.\nThen, use a webhook from ACR to trigger Jenkins after a successful build.\nGeneric Webhook Trigger Install the “Generic Webhook Trigger” plugin. The trigger URL looks like:\n1 http://\u0026lt;user\u0026gt;:\u0026lt;apiToken\u0026gt;@\u0026lt;jenkins-host\u0026gt;:8080/generic-webhook-trigger/invoke?token=\u0026lt;job-token\u0026gt; Set the same token under the job’s “Trigger builds remotely”. Disable CSRF protection if needed for webhook calls.\nFlow:\nrepo change → ACR auto build → ACR webhook → Jenkins job → deployment script pulls and runs the new image.\nDeployment step becomes:\n1 2 3 docker stop house-web || true \u0026amp;\u0026amp; docker rm house-web || true docker pull \u0026lt;your-acr-image\u0026gt; docker run --restart=always --name house-web \u0026lt;your-acr-image\u0026gt; Summary Stand up Jenkins. 2) Add Dockerfile. 3) Use ACR to build images. 4) Use ACR webhook → Jenkins to deploy. 5) Works for other stacks too — just change the Dockerfile. ","date":"2018-05-08T00:00:00Z","permalink":"https://liguobao.github.io/english/p/ci/cd-auto-deploy-.net-core-with-jenkins--docker/","title":"CI/CD Auto-Deploy .NET Core with Jenkins + Docker"},{"content":"Previously I posted on V2EX about this tool:\nNew interaction update for “Map‑based Rental Search”: https://www.v2ex.com/t/530011 Scraped “City”‑tagged sublet/rental posts into the app: https://www.v2ex.com/t/509447#reply8 Ad slot + major front‑end revamp + mini program live: https://www.v2ex.com/t/497674#reply4 Map‑based rental search: https://house-map.cn/#/ This time it’s for real. The earlier mini program failed qualification; later I teamed up with a classmate to ship it.\nFeatures City listings Screenshots show per‑city feeds and map overlays.\nPer‑platform views Group sources (e.g., different sites) with individual tabs.\nFiltered search Filter by administrative district Filter by “within N days” recency Filter by listing type + price Listing details + map Detail pages include map view/location.\nFavorites + feedback Star listings and submit feedback in‑app.\nWhat’s new (Beta 9) District filters; city‑only fallback when no district “Within N days” filter Listing type filter; combined with price Show publish time in lists Bug fixes + new bugs Faster loads via caching Added an “ad” slot About the ad slot It doesn’t earn much; cumulative project income over 2–3 years is around −¥10,000. ¯\\(ツ)/¯\nFollow the WeChat account “人生删除指南” to get the mini program, or scan the QR codes in the original post.\nNotes\nNewly launched; expect bugs. Thanks for your patience! Suggestions welcome via the account or email. Be kind :-) ","date":"2018-03-22T00:00:00Z","permalink":"https://liguobao.github.io/english/p/housemap-mini-program-launched/","title":"House‑Map Mini Program Launched"},{"content":"Consumers and Producers in ASP.NET Core Docs: http://www.rabbitmq.com/ — .NET client: http://www.rabbitmq.com/dotnet.html\nConsumer with IHostedService Run consumers with the app lifecycle using IHostedService.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 public class RabbitListener : IHostedService { private readonly IConnection _conn; private readonly IModel _channel; protected string RouteKey; protected string QueueName; public RabbitListener(IOptions\u0026lt;AppConfiguration\u0026gt; options) { var f = new ConnectionFactory { HostName = options.Value.RabbitHost, UserName = options.Value.RabbitUserName, Password = options.Value.RabbitPassword, Port = options.Value.RabbitPort, }; _conn = f.CreateConnection(); _channel = _conn.CreateModel(); } public Task StartAsync(CancellationToken ct) { Register(); return Task.CompletedTask; } public Task StopAsync(CancellationToken ct) { _conn.Close(); return Task.CompletedTask; } public virtual bool Process(string message) =\u0026gt; throw new NotImplementedException(); void Register() { _channel.ExchangeDeclare(exchange: \u0026#34;message\u0026#34;, type: \u0026#34;topic\u0026#34;); _channel.QueueDeclare(queue: QueueName, exclusive: false); _channel.QueueBind(queue: QueueName, exchange: \u0026#34;message\u0026#34;, routingKey: RouteKey); var consumer = new EventingBasicConsumer(_channel); consumer.Received += (m, ea) =\u0026gt; { var msg = Encoding.UTF8.GetString(ea.Body); if (Process(msg)) _channel.BasicAck(ea.DeliveryTag, false); }; _channel.BasicConsume(queue: QueueName, consumer: consumer); } } Subclass and resolve scoped services via IServiceProvider.CreateScope() inside Process.\nRegister: services.AddHostedService\u0026lt;YourListener\u0026gt;();\nProducer 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 public class RabbitMQClient { private readonly IModel _channel; private readonly ILogger _logger; public RabbitMQClient(IOptions\u0026lt;AppConfiguration\u0026gt; opts, ILogger\u0026lt;RabbitMQClient\u0026gt; logger) { var f = new ConnectionFactory { HostName = opts.Value.RabbitHost, UserName = opts.Value.RabbitUserName, Password = opts.Value.RabbitPassword, Port = opts.Value.RabbitPort, }; var conn = f.CreateConnection(); _channel = conn.CreateModel(); _logger = logger; } public void PushMessage(string routingKey, object message) { _logger.LogInformation($\u0026#34;PushMessage,routingKey:{routingKey}\u0026#34;); _channel.QueueDeclare(queue: \u0026#34;message\u0026#34;, durable: false, exclusive: false, autoDelete: false); var body = Encoding.UTF8.GetBytes(JsonConvert.SerializeObject(message)); _channel.BasicPublish(exchange: \u0026#34;message\u0026#34;, routingKey: routingKey, basicProperties: null, body: body); } } Register as singleton: services.AddSingleton\u0026lt;RabbitMQClient\u0026gt;();\n","date":"2018-01-15T00:00:00Z","permalink":"https://liguobao.github.io/english/p/using-rabbitmq-in-asp.net-core-the-right-way/","title":"Using RabbitMQ in ASP.NET Core the Right Way"},{"content":"Checklist and lessons moving workloads within/out of Tencent Cloud: networking, storage, DNS cutover, and monitoring.\n","date":"2018-01-01T00:00:00Z","permalink":"https://liguobao.github.io/english/p/migrating-services-on-tencent-cloud-notes/","title":"Migrating Services on Tencent Cloud — Notes"},{"content":"Using online schema changes to avoid downtime; tools and strategies (native InnoDB online DDL, gh-ost/pt-osc), caveats and verification.\n","date":"2018-01-01T00:00:00Z","permalink":"https://liguobao.github.io/english/p/mysql-online-ddl-practical-guide/","title":"MySQL Online DDL — Practical Guide"},{"content":"Highlights: using Helm charts, persistent storage, external access, runners, and upgrades. Common pitfalls and resource sizing.\n","date":"2018-01-01T00:00:00Z","permalink":"https://liguobao.github.io/english/p/running-gitlab-on-kubernetes-notes/","title":"Running GitLab on Kubernetes — Notes"},{"content":"Features overview and setup notes for SkyWalking’s commercial extensions.\n","date":"2018-01-01T00:00:00Z","permalink":"https://liguobao.github.io/english/p/skywalking-x-pack-notes/","title":"SkyWalking X-Pack — Notes"},{"content":"Create scopes inside background tasks and resolve DbContext from the scope to respect scoped lifetimes.\n","date":"2018-01-01T00:00:00Z","permalink":"https://liguobao.github.io/english/p/using-ef-dbcontext-in-background-tasks-ihostedservice/","title":"Using EF DbContext in Background Tasks (IHostedService)"},{"content":"Configuring signature, APIs, and common pitfalls when integrating the WeChat JS SDK in web apps.\n","date":"2018-01-01T00:00:00Z","permalink":"https://liguobao.github.io/english/p/wechat-js-sdk-integration-notes/","title":"WeChat JS SDK Integration Notes"},{"content":"Linux Ops Cheatsheet — Install, Config, and Quick Commands Ports \u0026amp; Processes 1 2 3 4 5 6 # Check what’s using a port netstat -anp | grep \u0026#34;5000\u0026#34; # Kill a process kill -9 2553 # Run in background nohup command \u0026amp; Install Shadowsocks (SS) 1 2 3 4 5 6 apt-get update # Install ss apt-get install python-pip pip install shadowsocks # Run ss server nohup ssserver -s \u0026lt;IP_ADDRESS\u0026gt; -k \u0026lt;PASSWORD\u0026gt; \u0026amp; Install MySQL 5.7 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Ref: http://tecadmin.net/install-mysql-5-on-ubuntu/ sudo apt-get install software-properties-common sudo add-apt-repository -y ppa:ondrej/mysql-5.7 sudo apt-get update sudo apt-get install mysql-server # Edit my.cnf to allow remote login # /etc/mysql/my.cnf # set bind-address = 0.0.0.0 # Restart MySQL /etc/init.d/mysql restart MySQL: Add Users 1 2 3 4 5 6 7 8 9 -- Grant all to root from anywhere GRANT ALL PRIVILEGES ON *.* TO \u0026#39;root\u0026#39;@\u0026#39;%\u0026#39; IDENTIFIED BY \u0026#39;root\u0026#39;; FLUSH PRIVILEGES; -- Example: specific privileges for a host GRANT SELECT,INSERT,UPDATE,DELETE,CREATE,DROP ON \u0026lt;db\u0026gt;.* TO \u0026#39;joe\u0026#39;@\u0026#39;10.163.225.87\u0026#39; IDENTIFIED BY \u0026#39;123\u0026#39;; -- Another example GRANT ALL ON xxxDB.* TO \u0026#39;xxx\u0026#39;@\u0026#39;%\u0026#39;; MySQL error: “Checking for tables which need an upgrade, are corrupt or were not closed cleanly” Steps:\n1 2 3 4 5 6 7 8 9 10 11 12 sudo service mysql stop sudo /etc/init.d/apparmor reload sudo service mysql start # Or: if multiple mysql instances/processes are running ps -A | grep mysql sudo pkill mysql ps -A | grep mysqld sudo pkill mysqld service mysql restart mysql -u root -p 7z Quick Ops 1 2 3 4 # Compress 7z a -t7z -r manager.7z /home/manager/* # Extract 7z x xx.zip Tencent Cloud: change password, allow root login 1 2 3 sudo passwd root sudo vi /etc/ssh/sshd_config sudo service ssh restart ","date":"2017-03-25T00:00:00Z","permalink":"https://liguobao.github.io/english/p/linux-ops-cheatsheet-install-config-and-quick-commands/","title":"Linux Ops Cheatsheet — Install, Config, and Quick Commands"},{"content":"Debugging PHP in VS Code (Windows) macOS guide: https://zhuanlan.zhihu.com/p/37128419\nStack: VS Code + PHP Debug extension + phpStudy + Xdebug.\nInstall VS Code Download from https://code.visualstudio.com/ and install.\nInstall PHP Debug extension Search for “PHP Debug” in the Marketplace and install it.\nphpStudy Use phpStudy for a quick PHP + Apache + MySQL stack. Switch PHP versions as needed.\nVerify phpMyAdmin opens and connects locally. Then pick your target PHP version.\nEnable Xdebug phpStudy ships with Xdebug. Open php.ini (Other options → Open config file → php-ini) and add:\n1 2 3 xdebug.remote_enable = 1 xdebug.remote_autostart = 1 zend_extension=\u0026#34;C:\\\\phpStudy\\\\php\\\\php-5.5.38\\\\ext\\\\php_xdebug.dll\u0026#34; Restart phpStudy services.\nVS Code settings and launch config Set php.validate.executablePath to your php.exe path (from phpStudy). Then add a PHP debug configuration (Listen for Xdebug) in launch.json.\nStart debugging, set breakpoints, and hit the target page — VS Code should break into the PHP code. Use F10/F11/F5 as usual.\nNotes for other stacks: configure php.ini, install the matching Xdebug DLL, and set php.validate.executablePath correctly.\n","date":"2017-03-17T00:00:00Z","permalink":"https://liguobao.github.io/english/p/debug-php-with-visual-studio-code-on-windows/","title":"Debug PHP with Visual Studio Code on Windows"},{"content":"A Hands-On Guide to Writing a Crawler with .NET Core Preface After migrating 58HouseSearch to .NET Core, I launched another side project, Dy2018Crawler, to crawl movie listings from dy2018. This post outlines the approach for building a crawler with .NET Core.\nSetup (.NET Core) Install the .NET Core SDK (cross‑platform). With SDK installed, any editor works. For convenience, the VS .NET Core templates are fine to start with.\nAnatomy of a Crawler Analyze the page Identify where the data lives in the HTML (ids, classes, attributes). For dy2018’s homepage, movie items live inside div.co_content222, with details in a elements.\nGoal: find the div.co_content222, then extract all a links from within.\nCode I use AngleSharp for HTML parsing in .NET.\nProject: https://anglesharp.github.io/ NuGet: Install-Package AngleSharp Fetch movie list 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 private static HtmlParser htmlParser = new HtmlParser(); private ConcurrentDictionary\u0026lt;string, MovieInfo\u0026gt; _cdMovieInfo = new ConcurrentDictionary\u0026lt;string, MovieInfo\u0026gt;(); private void AddToHotMovieList() { Task.Factory.StartNew(() =\u0026gt; { var htmlDoc = HTTPHelper.GetHTMLByURL(\u0026#34;http://www.dy2018.com/\u0026#34;); var dom = htmlParser.Parse(htmlDoc); var lstDivInfo = dom.QuerySelectorAll(\u0026#34;div.co_content222\u0026#34;); if (lstDivInfo != null) { foreach (var divInfo in lstDivInfo.Take(3)) { divInfo.QuerySelectorAll(\u0026#34;a\u0026#34;).Where(a =\u0026gt; a.GetAttribute(\u0026#34;href\u0026#34;).Contains(\u0026#34;/i/\u0026#34;)).ToList().ForEach(a =\u0026gt; { var onlineURL = \u0026#34;http://www.dy2018.com\u0026#34; + a.GetAttribute(\u0026#34;href\u0026#34;); // ... add to dictionary, etc. }); } } }); } Fetch movie details 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 private MovieInfo FillMovieInfoFormWeb(AngleSharp.Dom.IElement a, string onlineURL) { var movieHTML = HTTPHelper.GetHTMLByURL(onlineURL); var movieDoc = htmlParser.Parse(movieHTML); var zoom = movieDoc.GetElementById(\u0026#34;Zoom\u0026#34;); var lstDownLoadURL = movieDoc.QuerySelectorAll(\u0026#34;[bgcolor=\u0026#39;#fdfddf\u0026#39;]\u0026#34;); var updatetime = movieDoc.QuerySelector(\u0026#34;span.updatetime\u0026#34;); var pubDate = DateTime.Now; if (updatetime != null \u0026amp;\u0026amp; !string.IsNullOrEmpty(updatetime.InnerHtml)) { DateTime.TryParse(updatetime.InnerHtml.Replace(\u0026#34;发布时间：\u0026#34;, \u0026#34;\u0026#34;), out pubDate); } var movieInfo = new MovieInfo { MovieName = a.InnerHtml.Replace(\u0026#34;\u0026lt;font color=\\\u0026#34;#0c9000\\\u0026#34;\u0026gt;\u0026#34;,\u0026#34;\u0026#34;).Replace(\u0026#34;\u0026lt;font color=\\\u0026#34;\\t#0c9000\\\u0026#34;\u0026gt;\u0026#34;,\u0026#34;\u0026#34;).Replace(\u0026#34;\u0026lt;/font\u0026gt;\u0026#34;, \u0026#34;\u0026#34;), Dy2018OnlineUrl = onlineURL, MovieIntro = zoom != null ? WebUtility.HtmlEncode(zoom.InnerHtml) : \u0026#34;暂无介绍...\u0026#34;, XunLeiDownLoadURLList = lstDownLoadURL?.Select(d =\u0026gt; d.FirstElementChild.InnerHtml).ToList(), PubDate = pubDate, }; return movieInfo; } HTTPHelper dy2018 uses GB2312. .NET Core needs System.Text.Encoding.CodePages and Encoding.RegisterProvider(CodePagesEncodingProvider.Instance) to support it.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public static string GetHTMLByURL(string url) { try { var wRequest = System.Net.WebRequest.Create(url); wRequest.ContentType = \u0026#34;text/html; charset=gb2312\u0026#34;; wRequest.Method = \u0026#34;get\u0026#34;; var wResp = wRequest.GetResponseAsync().Result; using (var reader = new StreamReader(wResp.GetResponseStream(), Encoding.GetEncoding(\u0026#34;GB2312\u0026#34;))) { return reader.ReadToEnd(); } } catch { return string.Empty; } } Scheduled jobs Use Pomelo.AspNetCore.TimedJob for scheduled tasks.\nNuGet: Pomelo.AspNetCore.TimedJob Register in Startup:\n1 2 services.AddTimedJob(); app.UseTimedJob(); Define a job:\n1 2 3 4 5 6 7 8 public class AutoGetMovieListJob : Job { [Invoke(Begin = \u0026#34;2016-11-29 22:10\u0026#34;, Interval = 1000 * 3600 * 3, SkipWhileExecuting = true)] public void Run() { // logic } } Publish Adjust project.json (for older tooling) — add runtimes, comment out scripts (if Node/Bower not present), and remove type under Microsoft.NETCore.App.\nBuild \u0026amp; publish:\n1 2 dotnet restore dotnet publish -r ubuntu.14.04-x64 -c Release -o \u0026#34;C:\\\\code\\\\website\\\\Dy2018Crawler\u0026#34; Code: https://github.com/liguobao/Dy2018Crawler\nLive: http://codelover.win/\n","date":"2016-12-04T00:00:00Z","permalink":"https://liguobao.github.io/english/p/a-hands-on-guide-to-writing-a-crawler-with-.net-core/","title":"A Hands-On Guide to Writing a Crawler with .NET Core"},{"content":"Auto-Rebase Multiple Git Repositories When preparing releases, I often need to update several repos/branches before merging. Typing the same commands repeatedly gets old, so here’s a small shell script to rebase multiple repos in one go.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 printf \u0026#34;Start rebase 58HouseSearch.\\n\u0026#34; cd ./58HouseSearch git checkout master git pull --rebase origin master printf \u0026#34;Finish Pull Rebase 58HouseSearch master.\\n\u0026#34; read -p \u0026#34;Press any key to continue.\u0026#34; cd .. printf \u0026#34;Start rebase hexoforblog.\\n\u0026#34; cd ./hexoforblog git checkout master git pull --rebase origin master printf \u0026#34;Finish Pull Rebase hexoforblog.\\n\u0026#34; read -p \u0026#34;Press any key to continue.\u0026#34; cd .. Notes:\nprintf prints progress messages read -p pauses for confirmation between steps Output mirrors what you see in Git Bash ","date":"2016-11-25T00:00:00Z","permalink":"https://liguobao.github.io/english/p/script-to-auto-rebase-multiple-git-repositories/","title":"Script to Auto-Rebase Multiple Git Repositories"},{"content":"Preface Early on, JS went straight into script tags. As projects grew, we split into .js files and ordered \u0026lt;script\u0026gt; tags to model dependencies — brittle and blocking.\nRequireJS (AMD) addresses both: it loads modules asynchronously and manages dependencies explicitly.\nInclude RequireJS 1 \u0026lt;script src=\u0026#34;js/require.js\u0026#34; defer async=\u0026#34;true\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; Use data-main to specify the entry module:\n1 \u0026lt;script src=\u0026#34;js/require.js\u0026#34; data-main=\u0026#34;js/home\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; Configure In home.js:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 require.config({ baseUrl: \u0026#39;/DomainJS/\u0026#39;, paths: { jquery: \u0026#39;lib/jquery-1.11.3.min\u0026#39;, AMUI: \u0026#39;lib/amazeui.2.7.1.min\u0026#39;, \u0026#39;jquery.range\u0026#39;: \u0026#39;lib/jquery.range\u0026#39;, es5: \u0026#39;lib/es5\u0026#39;, mapController: \u0026#39;mapController\u0026#39;, addToolbar: \u0026#39;addToolbar\u0026#39; }, shim: { addToolbar: { deps: [\u0026#39;jquery\u0026#39;] }, \u0026#39;jquery.range\u0026#39;: { deps: [\u0026#39;jquery\u0026#39;] } } }); Load modules 1 2 3 4 5 6 7 8 9 10 require([\u0026#39;domready!\u0026#39;, \u0026#39;jquery\u0026#39;, \u0026#39;AMUI\u0026#39;, \u0026#39;mapController\u0026#39;, \u0026#39;city\u0026#39;, \u0026#39;commuteGo\u0026#39;], function (doc, $, AMUI, mapController, city, commuteGo) { city.initAllCityInfo(); mapController.init(); $(\u0026#34;input[name=\u0026#39;locationType\u0026#39;]\u0026#34;).on(\u0026#39;click\u0026#39;, mapController.locationMethodOnChange); $(\u0026#34;input[name=\u0026#39;vehicle\u0026#39;]\u0026#34;).on(\u0026#39;click\u0026#39;, commuteGo.go); // ... omitted ajax and UI code ... }); The first parameter lists dependencies; the callback runs after all load successfully.\nWrite AMD modules No deps:\n1 2 3 4 5 6 7 8 9 10 // helper.js define(function () { var getQueryString = function (name) { var reg = new RegExp(\u0026#39;(^|\u0026amp;)\u0026#39; + name + \u0026#39;=([^\u0026amp;]*)(\u0026amp;|$)\u0026#39;); var r = window.location.search.substr(1).match(reg); if (r != null) return unescape(r[2]); return null; }; return { getQueryString: getQueryString }; }); With deps:\n1 2 3 4 // marker.js define([\u0026#39;mapSignleton\u0026#39;, \u0026#39;city\u0026#39;, \u0026#39;transfer\u0026#39;], function (mapSignleton, city, transfer) { // ... }); For more on config and optimization, see:\nhttps://segmentfault.com/a/1190000002401665 https://segmentfault.com/a/1190000002403806 ","date":"2016-10-22T00:00:00Z","permalink":"https://liguobao.github.io/english/p/writing-modular-code-with-requirejs/","title":"Writing Modular Code with RequireJS"},{"content":"Commonly used Visual Studio shortcuts:\nCtrl+S — Save (the all‑time #1) Ctrl+Shift+S — Save all open files Ctrl+O — Open file Ctrl+Shift+O — Open project Ctrl+Shift+A — Add new item to current project Ctrl+F4 — Close current tab Ctrl+F6 — Next tab Ctrl+Shift+F6 — Previous tab F12 — Go to definition (functions/variables) Ctrl+– — Navigate back Shift+Ctrl+– — Navigate forward Ctrl+Tab — Switch tabs Ctrl+F — Find Ctrl+F3 — Find selection Ctrl+K, Ctrl+D — Format document Ctrl+K, Ctrl+F — Format selection Ctrl+K, Ctrl+C — Comment selection Ctrl+K, Ctrl+U — Uncomment selection Ctrl+L — Delete line / selection Shift+Alt+Enter — Toggle full screen for editor Ctrl+M, Ctrl+M — Toggle outlining (collapse/expand) Ctrl+Space — IntelliSense Ctrl+Enter — Insert line above Ctrl+Shift+Enter — Insert line below Shift+F12 — Find all references Ctrl+G — Go to line Ctrl+Shift+Up — Previous reference Ctrl+Shift+Down — Next reference Shift+Alt+Up — Column select upward Shift+Alt+Down — Column select downward Shift+Up — Extend selection up Shift+Down — Extend selection down ","date":"2016-10-14T00:00:00Z","permalink":"https://liguobao.github.io/english/p/visual-studio-shortcuts/","title":"Visual Studio Shortcuts"},{"content":"Installing “Microsoft .NET Core 1.0.0 VS 2015 Tooling Preview 2” was a bumpy ride. The bootstrapper downloads MSIs during install (online installer), but links were failing (502s) and network stability made it worse.\nWorkaround: download required packages manually and place them where the installer expects, or use an offline installer when available. For example, DotNetCore.1.0.1-SDK.1.0.0.Preview2-003133-x64.exe could be fetched via a reliable mirror/tool, while dependent MSIs were trickier due to broken links at the time.\nIf you hit 0x80070003 errors (path not found) during install, verify the cached package paths, disable unstable mirrors, and try a fully offline SDK installer. Alternatively, move to newer .NET Core SDK versions which have stable distribution and improved installers.\n","date":"2016-10-04T00:00:00Z","permalink":"https://liguobao.github.io/english/p/.net-core-1.0.0-vs2015-tooling-preview-2-0x80070003/","title":".NET Core 1.0.0 VS2015 Tooling Preview 2 — 0x80070003"},{"content":"Summary of proxyipcenter (by @virjar): a server that scrapes, de‑dupes, enriches, validates, and scores proxies; and a client that manages a per‑target pool for crawlers. See Chinese post for full details and JSON examples.\n","date":"2016-10-04T00:00:00Z","permalink":"https://liguobao.github.io/english/p/a-pragmatic-guide-to-proxy-ips-for-crawlers/","title":"A Pragmatic Guide to Proxy IPs for Crawlers"},{"content":"Tried ASP.NET Core with a teammate — here’s a quick hands‑on note.\nEnvironment: VS2015 Update 2 (any edition).\nDownload and install the .NET Core Runtime and SDK https://www.microsoft.com/net/download\nGrab both the .NET Core installer and the SDK, then install them (next, next, finish).\nInstall the VS2015 tooling (Preview 1 at the time) “.NET Core Tooling Preview 1 for Visual Studio 2015” https://go.microsoft.com/fwlink/?LinkId=798481\nThis one takes a bit longer — wait until it finishes.\nCreate a project Open VS → New Project → Web. You should now see the ASP.NET Core templates available. Create a project and you’re set. We’ll dive into ASP.NET Core project structure next time.\n","date":"2016-10-04T00:00:00Z","permalink":"https://liguobao.github.io/english/p/asp.net-core-first-look/","title":"ASP.NET Core — First Look"},{"content":"In classic ASP.NET, you might have touched HttpModule/HttpHandler for certain cross‑cutting needs. ASP.NET Core replaces them with Middleware and embraces a pipeline model — you’ll use middleware a lot.\nWhat is middleware? In Startup.Configure you compose the pipeline:\n1 2 3 4 5 6 7 8 9 10 11 12 public void Configure(IApplicationBuilder app, IHostingEnvironment env, ILoggerFactory loggerFactory) { loggerFactory.AddConsole(Configuration.GetSection(\u0026#34;Logging\u0026#34;)); loggerFactory.AddDebug(); app.UseStaticFiles(); app.UseMvc(routes =\u0026gt; { routes.MapRoute(\u0026#34;default\u0026#34;, \u0026#34;{controller=Home}/{action=Index}/{id?}\u0026#34;); }); } Each Use... adds a middleware. UseStaticFiles serves static files; UseMvc enables MVC routing. Remove UseMvc and controller routes won’t work.\nDifferences from HttpModule HttpModule used a fixed set of lifecycle events; you had to choose carefully where to plug in. Middleware is just code you write that receives HttpContext, can act, and then choose to call the next middleware.\nFlow The engine calls the first middleware’s Invoke(HttpContext), which can do work then call the next middleware, and so on. On the way back up the stack, you can also perform post‑processing.\nWrite a middleware 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public class SampleMiddleware { private readonly RequestDelegate _next; public SampleMiddleware(RequestDelegate next) =\u0026gt; _next = next; public async Task Invoke(HttpContext context) { if (string.IsNullOrEmpty(context.User.Identity.Name)) { context.Response.Redirect(\u0026#34;/NoName.html\u0026#34;); return; } await _next(context); } } Register it:\n1 2 3 4 5 6 7 8 9 10 public static class MiddlewareExtensions { public static IApplicationBuilder UseSampleMiddleware(this IApplicationBuilder builder) =\u0026gt; builder.UseMiddleware\u0026lt;SampleMiddleware\u0026gt;(); } // Startup.Configure app.UseStaticFiles(); app.UseSampleMiddleware(); app.UseMvc(...); Order matters Place UseSampleMiddleware before UseMvc so redirects happen before MVC routing. If you put it before UseStaticFiles and try to redirect to a static page, it will fail because static file serving hasn’t been added yet.\nInternals (high level) RequestDelegate represents a middleware delegate. IApplicationBuilder.Use(...) chains delegates into a stack; UseMiddleware\u0026lt;T\u0026gt; validates your type (has a single Invoke(HttpContext)) and builds the delegate. When the host starts, the pipeline is built once (Build/Run) and reused per request.\n","date":"2016-10-04T00:00:00Z","permalink":"https://liguobao.github.io/english/p/asp.net-core-middleware-concepts-order-and-internals/","title":"ASP.NET Core Middleware — Concepts, Order, and Internals"},{"content":"Bookmark Memorandum Markdown references Markdown (Simplified Chinese): http://wowubuntu.com/markdown/ Markdown Basics (quick start): http://wowubuntu.com/markdown/basic.html Build a free static blog (GitHub + Hexo) Guide: http://wsgzao.github.io/post/hexo-guide/ Install Hexo\n1 2 3 4 5 npm install hexo-cli -g npm install hexo --save # If npm is slow, try the taobao registry npm install -g cnpm --registry=https://registry.npm.taobao.org Install Hexo plugins\n1 2 3 4 5 6 7 8 9 10 11 12 13 npm install hexo-generator-index --save npm install hexo-generator-archive --save npm install hexo-generator-category --save npm install hexo-generator-tag --save npm install hexo-server --save npm install hexo-deployer-git --save npm install hexo-deployer-heroku --save npm install hexo-deployer-rsync --save npm install hexo-deployer-openshift --save npm install hexo-renderer-marked@0.2 --save npm install hexo-renderer-stylus@0.2 --save npm install hexo-generator-feed@1 --save npm install hexo-generator-sitemap@1 --save Git tips Fix “Filename too long” on Windows\n1 git config --global core.longpaths true Git + SSH usage: https://segmentfault.com/a/1190000002645623\n","date":"2016-10-04T00:00:00Z","permalink":"https://liguobao.github.io/english/p/bookmark-memorandum/","title":"Bookmark Memorandum"},{"content":"C# Avoid Throwing Exceptions in Functions or Operations Introduction In some scenarios, your function or operation needs to operate on a sequence of objects, and an exception is thrown during the process. At this time, if there is no data such as status records, we do not know how much data has been processed, nor do we know what strategy to use to roll back, so we cannot return to the previous state.\nLet\u0026rsquo;s look at the following code:\n1 2 var allEmp = FindAllEmployees(); allEmp.ForEach(e =\u0026gt; e.MonthlySalary *=1.05M); This code looks fine. But one day, when this program runs, an exception is thrown. The location where the exception is thrown may be unknown, causing some employees to get a raise, while others do not. The result is that except for manually checking the data, we have no way to recover the lost state.\nThis way of modifying elements leads to the above problem. This code does not follow the \u0026ldquo;strong exception safety guarantee\u0026rdquo; rule. In other words, when an error occurs at runtime, we cannot know what happened and what did not happen.\nPrinciple: If we can guarantee that the program\u0026rsquo;s state will not change when the method cannot complete, such problems will not occur. We have several methods to achieve this requirement, but each method has its own advantages and risks.\nThrowing Exceptions in Functions/Operations Obviously, not all methods will encounter such problems (exceptions leading to state loss). Many times we just check the elements in the sequence, access them without modifying them. We don\u0026rsquo;t need to be too careful about this kind of behavior. Now let\u0026rsquo;s go back to the beginning, for the above scenario (giving each employee a 5% raise), if we want to follow the \u0026ldquo;strong exception safety guarantee\u0026rdquo; principle, how should we modify this method?\nFirst exception: Exception when getting data In the above example, even if the FindAllEmployees() function throws an exception, causing us to fail to correctly give employees a raise. Although this situation does not cause problems with our data, the people who should get a raise did not get it, which is a frustrating thing.\nSolution: Rewrite the operation method given earlier with lambda expression (i.e. FindAllEmployees() method), so that it never throws an exception. Many times, before we start modifying data, it is not very difficult to validate the legitimacy of the data and exclude erroneous data (if allowed). We can take this approach to achieve our goal. But here, we must strictly handle the operation method so that it can meet the needs in all situations.\nSecond exception: Exception in lambda expression when operating data Also in the above example, if we throw an exception when executing the raise operation, raising the salary of those employees who have already resigned, causing the program to interrupt and lose state. In this case, filtering out resigned employees before executing the raise operation is a correct approach.\nSolution: Validate and filter before operating data Such as:\nallEmp.Where(emp=\u0026gt;emp.Active).ForEach(e =\u0026gt; e.MonthlySalary *=1.05M);\nThird exception: Exception when executing operation Sometimes, we cannot guarantee whether an exception will be thrown when processing. At this time, we must adopt some more expensive processing methods.\nSolution: Create a copy to try the operation, and execute the real operation after the copy is correct When writing this kind of code, we should consider the handling plan after throwing an exception. This means that our operation should first execute on the original data copy, and then replace the original data only after the operation succeeds.\nSuch as:\n1 2 3 4 5 6 7 8 9 var updatas = (from e in allEmp select new Emp { EmpID=e.EmpID, ...... MonthlySalary =e.MonthlySalary *=1.05M }).ToList(); allEmp = updatas; But such modifications also cause other problems: the amount of code increases, and generating copies also consumes a lot of resources. Such an approach also has a benefit, when we encounter exceptions when operating on copy data, we have ample \u0026ldquo;space\u0026rdquo; to handle these data.\nIn practice, this means that we let the query expression return a new sequence instead of modifying the elements in the original sequence. In this way, we try to complete all operations at the same time, even if it fails, it will not affect the original state of our program.\n","date":"2016-10-04T00:00:00Z","permalink":"https://liguobao.github.io/english/p/c%23-avoid-throwing-exceptions-in-functions-or-operations/","title":"C# Avoid Throwing Exceptions in Functions or Operations"},{"content":"C# Class Fields and Properties Fields Fields represent read-only or readable/writable data values. Fields can be static, which are considered part of the type state. Fields can also be instance (non-static), which are considered part of the object state. It is strongly recommended to declare fields as private to prevent the type or object\u0026rsquo;s state from being corrupted by external code. Properties Properties allow setting or querying the logical state of a type or object using simple, field-style syntax, while ensuring the state is not corrupted. Properties that act on types are called static properties, and those that act on objects are called instance properties. Properties can have no parameters or multiple parameters (rare, but common in collection classes).\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 using System; public sealed class SomeType { // 1 // Nested class private class SomeNestedType { } // 2 // Constant, read­only, and static read/write field private const Int32 c_SomeConstant = 1; // 3 private readonly String m_SomeReadOnlyField = \u0026#34;2\u0026#34;; // 4 private static Int32 s_SomeReadWriteField = 3; // 5 // Type constructor static SomeType() { } // 6 // Instance constructors public SomeType(Int32 x) { } // 7 public SomeType() { } // 8 // Instance and static methods private String InstanceMethod() { return null; } // 9 public static void Main() { } // 10 // Instance property public Int32 SomeProp { // 11 get { return 0; } // 12 set { } // 13 } // Instance parameterful property (indexer) public Int32 this[String s] { // 14 get { return 0; } // 15 set { } // 16 } // Instance event public event EventHandler SomeEvent; // 17 } ","date":"2016-10-04T00:00:00Z","permalink":"https://liguobao.github.io/english/p/c%23-class-fields-and-properties/","title":"C# Class Fields and Properties"},{"content":"It may be because we are all accustomed to explicit definitions. Generally speaking, in daily life, we rarely use anonymous objects.\nHowever, for implementing those short-lived types that do not dominate the application logic, using anonymous objects is a good choice. On the other hand, it may also be because the life cycle of anonymous types cannot span the method containing the type, which makes many people feel that anonymous objects are not easy to use because they cannot be passed between multiple methods.\nThis is not accurate. We can completely write generic methods for anonymous types. However, if so, we cannot handle any special elements or write any special logic in the generic type method.\nBelow we will write a simple example, the example function: return all elements in the collection that are equal to the object to be found.\n1 2 3 4 5 6 7 8 static IEnumerable\u0026lt;T\u0026gt; FindValue(IEnumerable\u0026lt;T\u0026gt; enumerable, T value) { foreach (T element in enumerable) { if (element.Equals(value)) yield return element; } } This method can be used with anonymous types, but this method is essentially a generic method and does not understand the information of anonymous types.\n","date":"2016-10-04T00:00:00Z","permalink":"https://liguobao.github.io/english/p/c%23-define-local-functions-for-anonymous-types/","title":"C# Define Local Functions for Anonymous Types"},{"content":"Join Quick notes on inner/left/right/outer joins — focusing on LINQ’s Join and Enumerable.Join.\nEnumerable.Join signature:\n1 2 3 4 5 6 public static IEnumerable\u0026lt;TResult\u0026gt; Join\u0026lt;TOuter, TInner, TKey, TResult\u0026gt;( this IEnumerable\u0026lt;TOuter\u0026gt; outer, IEnumerable\u0026lt;TInner\u0026gt; inner, Func\u0026lt;TOuter, TKey\u0026gt; outerKeySelector, Func\u0026lt;TInner, TKey\u0026gt; innerKeySelector, Func\u0026lt;TOuter, TInner, TResult\u0026gt; resultSelector) Where:\nouter/inner: sequences to join outerKeySelector/innerKeySelector: key selectors resultSelector: projector for the joined pair MSDN-style example:\n1 2 3 4 5 6 7 var query = people.Join( pets, person =\u0026gt; person, pet =\u0026gt; pet.Owner, (person, pet) =\u0026gt; new { OwnerName = person.Name, Pet = pet.Name }); foreach (var x in query) Console.WriteLine($\u0026#34;{x.OwnerName} - {x.Pet}\u0026#34;); LINQ query syntax equivalent (inner join):\n1 2 3 var query = from person in people join pet in pets on person equals pet.Owner select new { OwnerName = person.Name, Pet = pet.Name }; Left join via GroupJoin:\n1 2 3 var queryGroup = from person in people join pet in pets on person equals pet.Owner into ps select new { OwnerName = person.Name, Pet = ps }; References:\nhttps://msdn.microsoft.com/zh-cn/library/bb311040.aspx https://msdn.microsoft.com/zh-cn/library/bb534675(v=vs.110).aspx ","date":"2016-10-04T00:00:00Z","permalink":"https://liguobao.github.io/english/p/c%23-join-and-linq-join-basics/","title":"C# Join and LINQ Join Basics"},{"content":"LINQ Advantages Summary (Reprint) Original link: http://www.cnblogs.com/c-jquery-linq-sql-net-problem/archive/2011/01/15/LINQ_Merit.html\nI\u0026rsquo;ve been reading a book on LINQ called \u0026lsquo;Essential LINQ\u0026rsquo;, and here I share it with everyone.\nSince a deep summary of LINQ requires a lot of space, I\u0026rsquo;ll divide it into several parts here.\n(*I read the English version of \u0026lsquo;Essential LINQ\u0026rsquo;, please forgive me if some terms cannot be translated into proper Chinese explanations)\nAdvantages of LINQ:\nLINQ basically has the following seven advantages, let me illustrate them one by one:\nIntegrated: The so-called Integrated (integration), LINQ embodies integration from the following aspects: (1): Integrate query syntax into languages like C#(VB), making it a syntax. This way, it can support the same as other syntax in C#:\nStatement highlighting, type checking, allowing debugger debugging\n(2): Integrate and encapsulate the previous complex pre-query work, allowing developers to focus on the query.\n(3): The integrated syntax is clearer and more readable.\n1 2 3 4 5 6 7 8 9 10 11 12 Comparison: //Original format SqlConnection sqlConn = new SqlConnection(connectionString);\u0026gt; sqlConn.Open(); SqlCommand command = new SqlCommand(); command.Connection = sqlConn; command.CommandText = \u0026#34;Select * From Customer\u0026#34;; SqlDataReader dataReader = command.ExecuteReader(CommandBehavior.CloseConnection); //LINQ format NORTHWNDDataContext dc = new NORTHWNDDataContext(); var query = from c in dc.Customers select c; Unitive: The so-called Unitive (unification) means using unified query syntax for any type of external and internal data sources (object collections, xml, database data). The benefits of using a unified query language are as follows:\nYou don\u0026rsquo;t have to spend a lot of effort learning unfamiliar data sources, you can quickly and simply use LINQ syntax to query them.\nSince unified syntax is used, code maintenance becomes simpler.\nThe following code embodies LINQ\u0026rsquo;s unification:\n1 2 3 4 5 6 7 8 9 10 //Data source: object collection var query = from c in GetCustomers() select c; //Data source: SQL var query1 = from c in dc.Customers select c; //Data source: XML var query2 = from c in customers.Descendants(\u0026#34;Customer\u0026#34;) select c; Extensible: The so-called Extensible (extensibility) refers to the following 2 aspects: (1). Extension of queryable data sources. LINQ provides a LINQ provider model, you can create or provide providers for LINQ to support more data sources.\n(2). Extensible query methods. Developers can rewrite and extend query methods for LINQ according to their own needs.\nHere are some third-party LINQ providers:\nLINQ Extender, LINQ to JavaScript, LINQ to JSON, LINQ to MySQL, LINQ to Flickr, LINQ to Google\nDeclarative: The so-called Declarative (declarative), simply put, means that developers only tell the program what to do, and the program judges how to do it. The advantages of Declarative programming are reflected in the following 2 points:\n(1). Improve development speed. Because developers don\u0026rsquo;t need to write a lot of code to concretize execution steps, just tell the program what to do.\n(2). Improve code optimization space. Because developers don\u0026rsquo;t interfere with the specific steps of program execution, this provides more space for the compiler to optimize the code.\nFor example, in SQL, LINQ-generated SQL statements are often better than SQL statements written by developers with average SQL skills.\nCompare Declarative programming with Imperative programming:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 //Declarative programming List\u0026lt;List\u0026lt;int\u0026gt;\u0026gt; lists = new List\u0026lt;List\u0026lt;int\u0026gt;\u0026gt; { new List\u0026lt;int\u0026gt; { 1, 2, 3 }, new List\u0026lt;int\u0026gt; { 4, 5 } }; var query = from list in lists from num in list where num % 3 == 0 orderby num descending select num; //Imperative programming List\u0026lt;int\u0026gt; list1 = new List\u0026lt;int\u0026gt;(); list1.Add(1); list1.Add(2); list1.Add(3); List\u0026lt;int\u0026gt; list2 = new List\u0026lt;int\u0026gt;(); list2.Add(4); list2.Add(5); List\u0026lt;List\u0026lt;int\u0026gt;\u0026gt; lists1 = new List\u0026lt;List\u0026lt;int\u0026gt;\u0026gt;(); lists1.Add(list1); lists1.Add(list2); List\u0026lt;int\u0026gt; newList = new List\u0026lt;int\u0026gt;(); foreach (var item in lists1) foreach (var num in item) if (num % 3 == 0) newList.Add(num); newList.Reverse(); Hierarchical: The so-called Hierarchical (hierarchical) refers to abstracting data in an object-oriented way. SQL is a relational database, it describes data and data relationships in a relational way, but our programs are designed to be object-oriented, so the database data we get in the program are often rectangular grid (planar display data). But LINQ converts relational to object-to-object description of data through the so-called O-R Mapping method.\nThe benefits are: Developers can directly operate data in an object way, and for developers accustomed to object-oriented, the object-oriented model is easier to understand.\nComposable: The so-called Composable (composable) means that LINQ can split a complex query into multiple simple queries. The results returned by LINQ are all based on the interface: IEnumerable, so you can continue querying the query results, and LINQ has the characteristic of deferred execution, so splitting execution will not affect efficiency.\nThe advantages are:\n(1). Convenient debugging. Split complex queries into simple queries, then debug them one by one.\n(2). Easy code maintenance. Splitting the code can make the code easier to understand.\nThe following code embodies composability:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 //The following code embodies Composable List\u0026lt;List\u0026lt;int\u0026gt;\u0026gt; lists = new List\u0026lt;List\u0026lt;int\u0026gt;\u0026gt; { new List\u0026lt;int\u0026gt; { 1, 2, 3 }, new List\u0026lt;int\u0026gt; { 4, 5 } }; var query1 = from list in lists from num in list select num; var query2 = from num in query1 where num % 3 == 0 select num; var query3 = from num in query2 orderby num descending select num; Transformative: The so-called Transformative (transformative) means that LINQ can convert the content of one data source to other data sources. Convenient for users to do data migration.\nThe following code embodies the transformation feature:\n1 2 3 4 5 6 //Convert relational data to XML type var query = new XElement(\u0026#34;Orders\u0026#34;, from c in dc.Customers where c.City == \u0026#34;Paris\u0026#34; select new XElement(\u0026#34;Order\u0026#34;, new XAttribute(\u0026#34;Address\u0026#34;, c.Address))); The above are the main advantages of LINQ, I\u0026rsquo;m glad to share here with everyone. If there are any shortcomings, please supplement and correct, thank you for visiting the hut.\n//2011/1/28 Supplement (LINQ TO SQL)\nIn terms of LINQ TO SQL, if you use LINQ TO SQL, you can effectively prevent SQL injection, LINQ TO SQL will treat the injected code as useless parameters.\nhttp://www.cnblogs.com/c-jquery-linq-sql-net-problem/archive/2011/01/15/LINQ_Merit.html\n","date":"2016-10-04T00:00:00Z","permalink":"https://liguobao.github.io/english/p/c%23-linq-advantages-summary-reprint/","title":"C# LINQ Advantages Summary (Reprint)"},{"content":"First look at a piece of code\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 #region test1 Closure public static void test1() { int index = 0; Func\u0026lt;IEnumerable\u0026lt;int\u0026gt;\u0026gt; sequence =()=\u0026gt;GetEnumrableInt(index); index = 20; foreach(int n in sequence()) Console.WriteLine(n); Console.WriteLine(\u0026#34;Done\u0026#34;); index = 100; foreach (int n in sequence()) Console.WriteLine(n); } public static IEnumerable\u0026lt;int\u0026gt; GetEnumrableInt(int index) { List\u0026lt;int\u0026gt; l = new List\u0026lt;int\u0026gt;(); for(int i=index;i\u0026lt;index+30;i++) { l.Add(i); } return l; } #endregion The above code demonstrates the situation where external variables are used in closures, and then these variables are modified externally, resulting in outputting numbers from 20-50, and then outputting numbers between 100-130. This behavior is a bit weird, but it does have meaning\u0026hellip; (The book says so, I think it\u0026rsquo;s rarely used.)\nTo convert query expressions into executable code, the C# compiler does a lot of work. Generally speaking, the C# compiler converts queries and lambda expressions into \u0026ldquo;static delegates\u0026rdquo;, \u0026ldquo;instance delegates\u0026rdquo; or \u0026ldquo;closures\u0026rdquo;. The compiler will choose an implementation method based on the code in the lambda expression. Which method is chosen depends on the body of the lambda expression. This seems to be some implementation details of the language, but it can significantly affect our code. The choice of implementation by the compiler may lead to subtle changes in behavior.\nNot all lambda expressions generate code with the same structure.\nFor the compiler, the simplest behavior is to generate delegates for code in the following form.\n1 2 3 4 5 6 7 8 9 10 11 12 //Our lambda expression public static void test2() { int[] someNum = {0,1,2,3,4,5,6,7,8,9,10 }; IEnumerable\u0026lt;int\u0026gt; ans = from n in someNum select n * n; foreach (int i in ans) Console.WriteLine(i); } The compiler will use static delegates to implement the n*n lambda expression, and the code generated for the above code is as follows:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 //Code generated by the compiler for our lambda #region Equivalent to test2() private static int HiddenFunc(int n) { return n * n; } //Static delegate private static Func\u0026lt;int, int\u0026gt; HiddenDelegate; public void test2_1() { int[] someNum = { 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10 }; if(HiddenDelegate==null) { HiddenDelegate = new Func\u0026lt;int, int\u0026gt;(HiddenFunc); } IEnumerable\u0026lt;int\u0026gt; ans = someNum.Select\u0026lt;int, int\u0026gt;(HiddenDelegate); foreach(int i in ans) Console.WriteLine(i); } #endregion The body of this lambda expression does not access any instance variables or local variables. The lambda expression only accesses its parameters. In this case, the C# compiler will create a static method as the target of the delegate. This is also the simplest processing performed by the compiler. If the expression can be implemented through a private static method, the compiler will generate the private static method and the corresponding delegate definition. For the code example above and expressions that only access static variables, the compiler will adopt this approach.\nNext, introduce another relatively simple situation:\nThe lambda expression needs to access the instance variables of the type, but does not need to access the local variables in the outer method.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 public class ModFilter { private readonly int modules; public ModFilter(int mod) { modules = mod; } public IEnumerable\u0026lt;int\u0026gt; FindValues(IEnumerable\u0026lt;int\u0026gt; sequence) { return from n in sequence where n % modules == 0 //Newly added expression select n * n; //Same as the previous example } } /* In this case, the compiler will create an instance method to wrap the delegate for the expression. The basic concept is the same as the previous case, except that an instance method is used here to read and modify the state of the current object. Like the static delegate example, here the compiler will convert the lambda expression into familiar code. Which includes the definition of the delegate and the method call. As follows: */ public class ModFilter_Other { private readonly int modules; //Instance method private bool WhereClause(int n) { return ((n%this.modules) ==0); } private static int SelectClause(int n) { return n * n; } private static Func\u0026lt;int, int\u0026gt; SelectDelegate; public ModFilter_Other(int mod) { modules = mod; } public IEnumerable\u0026lt;int\u0026gt; FindValues(IEnumerable\u0026lt;int\u0026gt; sequence) { if(SelectDelegate==null) { SelectDelegate = new Func\u0026lt;int, int\u0026gt;(SelectClause); } return sequence.Where\u0026lt;int\u0026gt;( new Func\u0026lt;int, bool\u0026gt;(this.WhereClause)). Select\u0026lt;int, int\u0026gt;(SelectClause); } } In summary: If the code in the lambda expression accesses member variables in the object instance, then the compiler will generate instance methods to represent the code in the lambda expression. In fact, there is nothing special about this—the compiler saves us some code input work, and the code becomes much cleaner. Essentially, this is still an ordinary method call.\nHowever, if the lambda expression accesses local variables or method parameters in the outer method, then the compiler will do a lot of work for you.\nClosures are used here. The compiler will generate a private nested type to implement closures for local variables.\nLocal variables must be passed into the delegate that implements the body of the lambda expression.\nIn addition, all modifications made by the lambda expression to these local variables must be accessible externally.\nOf course, there may be more than one variable shared between the inner and outer layers in the code, and there may be more than one query expression.\nLet\u0026rsquo;s modify the instance method to access a local variable.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 public class ModFilter { private readonly int modules; public ModFilter(int mod) { modules = mod; } public IEnumerable\u0026lt;int\u0026gt; FindValues(IEnumerable\u0026lt;int\u0026gt; sequence) { int numValues = 0; return from n in sequence where n % modules == 0 //Newly added expression select n * n / ++ numValues; //Access local variable } } Note that the select clause needs to access the local variable numValues. In order to create this closure, the compiler needs to use a nested type to implement the behavior you need. Below is the code generated by the compiler for you. public class ModFilter { private sealed class Closure { public ModFilter outer; public int numValues; public int SelectClause(int n) { return ((n * n) / ++this.numValues); } } private readonly int modules; //Instance method private bool WhereClause(int n) { return ((n % this.modules) == 0); } public ModFilter(int mod) { modules = mod; } public IEnumerable\u0026lt;int\u0026gt; FindValues(IEnumerable\u0026lt;int\u0026gt; sequence) { Closure c = new Closure(); c.outer = this; c.numValues = 0; return sequence.Where\u0026lt;int\u0026gt;( new Func\u0026lt;int, bool\u0026gt;(this.WhereClause)). Select\u0026lt;int, int\u0026gt;(c.SelectClause); } } In the above code, the compiler specifically creates a nested class to contain all variables that will be accessed or modified in the lambda expression. In fact, these local variables will be completely replaced by the fields of the nested class. The code inside the lambda expression and the code outside (but still in the current method) access the same field, and the logic in the lambda expression is also compiled into a method of the inner class.\nFor the parameters of the outer method that will be used in the lambda expression, the compiler will also implement them in the same way as local variables: the compiler will copy these parameters into the nested class representing the closure.\nGoing back to the initial example, this is something we should be able to understand this seemingly strange behavior. The variable index was passed into the closure, but was modified by external code before the query started executing. That is to say, you modified the internal state of the closure, and then expected it to return to its previous state to start executing, which is obviously impossible.\nConsidering the interaction in deferred execution and the way the compiler implements closures, modifying variables bound between the query and external code may cause erroneous behavior.\nTherefore, we should try to avoid modifying variables in methods that will be passed into closures and used in closures.\n","date":"2016-10-04T00:00:00Z","permalink":"https://liguobao.github.io/english/p/c%23-tips-to-avoid-modifying-bound-variables/","title":"C# Tips to Avoid Modifying Bound Variables"},{"content":".NET Managed Heap and Garbage Collection Basics of Managed Heap Brief description: Every program needs to use resources of one kind or another, including files, memory buffers, screen space, network connections\u0026hellip;.. In fact, in an object-oriented environment, each type represents a resource available to the program. To use these resources, memory must be allocated for the type representing the resource.\nThe following are the steps required to access a resource:\nCall the IL instruction newobj to allocate memory for the type representing the resource. (C# new operator) Initialize the memory to set the initial state of the resource. (Generally refers to the constructor) Access the type\u0026rsquo;s members to use the resource. (Use member variables, methods, properties, etc.) Destroy the resource\u0026rsquo;s state for cleanup. (Dispose???) Free the memory. (GC) Allocating Resources from the Managed Heap CLR requires all objects to be allocated from the managed heap.\nWhen the process initializes, CLR allocates an address space region as the managed heap. CLR also maintains a pointer, let\u0026rsquo;s call it NextObjPtr, which points to the allocation position of the next object in the heap. At the beginning, NextObjPtr is set to the base address of the address space region.\nWhen a region is filled with non-garbage objects, CLR allocates more regions.\nThis process repeats until the entire process address space is filled. So, application memory is limited by the process\u0026rsquo;s virtual address space.\n32-bit processes can allocate up to 1.5GB, 64-bit processes can allocate up to 8T.\nNote: Related materials on process memory size\nMemory Support and Windows Operating Systems\nProcess Address Space\nMaximum memory available for C/C++ programs in 32-bit mode\nThe new operator in C# causes CLR to perform the following operations: Calculate the number of bytes required for the type\u0026rsquo;s fields (and fields inherited from base types).\nAdd the bytes required for object overhead. Each object has two overhead fields: type object pointer and sync block index. For 32-bit applications, these two fields each require 32 bits, so each object needs to add 8 bytes. For 64-bit applications, these two fields each require 64 bits, so each object adds 16 bytes.\nCLR checks if there are enough bytes in the region to allocate the object. If the managed heap has enough available space, the object is placed at the address pointed to by the NetxObjPtr pointer, and the bytes allocated for the object are zeroed. Then the type\u0026rsquo;s constructor is called (passing NextObjPtr as the this parameter), the new operator returns the object reference. Just before returning the object reference, the value of the NextObjPtr pointer is increased by the number of bytes occupied by the object to get a new value, which is the address where the next object will be placed in the managed heap. As shown in the figure:\nGarbage Collection Algorithm CLR uses reference tracking algorithm. Reference tracking algorithm only cares about reference type variables, because only this type of variable can reference objects on the heap;\nValue type variables directly contain value type instances. Reference type variables can be used in many situations, including static and instance fields of classes, or parameters and local variables of methods. Here we call all reference type variables roots.\nWhen CLR starts GC, it first suspends all threads. (This prevents threads from accessing objects and changing their state during CLR inspection.) Then CLR enters the GC marking phase. In this phase, CLR traverses all objects in the heap, setting a bit in the sync block index field to 0. This indicates that all objects should be deleted. Then, CLR checks all active roots to see which objects they reference. This is why CLR\u0026rsquo;s GC is called reference tracking GC. If a root contains null, CLR ignores this root and continues to check the next root.\nThe figure below shows a heap containing several objects.\nThe application\u0026rsquo;s roots directly reference objects A, C, D, F. All objects have been marked. When marking object D, GC finds that this object contains a field referencing object H, causing object H to also be marked. The marking process continues until all roots of the application have been checked.\nAfter checking, the objects in the heap are either marked or unmarked. Marked objects cannot be garbage collected because at least one root is referencing them. We say that such objects are reachable because the application can reach them through variables referencing them. Unmarked objects are unreachable because there is no root in the application that can make the object accessible again.\nAfter CLR knows which objects can survive and which can be deleted, it enters the GC compression (similar to defragmentation) phase. In the compression phase, CLR \u0026ldquo;moves\u0026rdquo; the marked objects in the heap to organize all surviving objects to occupy contiguous memory.\nThe benefits of doing this are:\nAll surviving objects are next to each other in memory, restoring the \u0026ldquo;locality\u0026rdquo; of references, reducing the application\u0026rsquo;s working set, thereby improving performance when accessing these objects in the future;\nAfter defragmentation, the available space is also contiguous, liberating the entire address space segment, allowing other things to reside.\nAfter moving objects in memory, there is a problem that needs to be solved urgently. The roots referencing surviving objects now reference the original location of the object in memory, not the moved location. When suspended threads resume execution, they will access the old memory location, causing memory corruption. This is obviously intolerable, so as part of the compression phase, CLR also subtracts the number of bytes the referenced object is offset in memory from each root. This ensures that each root still references the same object as before, only the object\u0026rsquo;s position in memory has changed.\nAs shown in the figure:\nGenerations: Improving Performance (To be continued) CLR\u0026rsquo;s GC is a generational garbage collector, it makes the following assumptions about your code:\nThe newer the object, the shorter the lifetime.\nThe older the object, the longer the lifetime.\nRecycling part of the heap is faster than recycling the entire heap.\nExtensive research shows that these assumptions hold for most applications today, and they affect the implementation of the garbage collector. Here we will explain how generations work.\nThe managed heap does not include objects when initialized. Objects added to the heap become generation 0 objects. Simply put, generation 0 objects are those newly constructed objects that the garbage collector has never checked. As shown in the figure, a newly started application has allocated 5 objects (A to E). After a while, C and E become unreachable.\nCLR initializes generation 0 objects by selecting a budget capacity. If allocating a new object causes generation 0 to exceed the budget, a GC must be started. Assuming objects A to E just fill generation 0\u0026rsquo;s space, allocating object F must start GC. After GC, surviving objects become generation 1 objects. As shown in the figure:\nAfter one GC, generation 0 does not contain any objects. As before, new objects will be allocated to generation 0. Newly allocated objects F to K all go to generation 0.\nThen, the program continues to run, B, H, J become unreachable, their memory will be recycled at some point.\nAssume that allocating new object L will cause generation 0 to exceed the budget, causing GC to start.\nWhen starting garbage collection, the garbage collector must decide which generations to check. As mentioned earlier, CLR initializes by selecting a budget for generation 0 objects. In fact, it must also select a budget for generation 1.\nWhen starting a garbage collection, the garbage collector also checks how much memory generation 1 occupies. In this example, since generation 1 occupies much less memory than the budget, the garbage collector decides to check only generation 0 objects. Recalling the first assumption made by the generational garbage collector: the newer the object, the shorter the lifetime. Therefore, generation 0 contains more garbage, and more memory can be recycled. By ignoring objects in generation 1, the garbage collection speed is accelerated.\nObviously, ignoring objects in generation 1 can improve the performance of the garbage collector. But what has a greater performance boost is that now there is no need to traverse every object in the managed heap. If a root or object references an object in an older generation, the garbage collector can ignore all references inside the old object, and can construct the reachable object graph in a shorter time. Of course, if the fields of old objects may also reference new objects. To ensure that updated fields of old objects are checked, the garbage collector uses a mechanism inside the JIT compiler. This mechanism sets a corresponding flag when the reference field of an object changes. In this way, the garbage collector knows which old objects (if any) have been written to since the last garbage collection. Only old objects whose fields have changed need to be checked to see if they reference any new objects in generation 0.\nThe generational garbage collector also assumes that the older the object, the longer it lives. That is, generation 1 objects are likely to continue to be reachable in the application. If the garbage collector checks the objects in generation 1, it is likely to find little garbage, and as a result, little memory can be recycled. Therefore, garbage collecting generation 1 is likely to be a waste of time. If there is really garbage in generation 1, the garbage will stay there. As shown in the figure:\nThe program continues to run, continues to allocate objects to generation 0, and at the same time the program stops using some objects in generation 1.\nAs shown in the figure:\nAllocating object P causes generation 0 to exceed the budget, starting GC. All objects in generation 1 still occupy less than the budget, the garbage collector decides again to recycle only generation 0. Ignore garbage objects in generation 1. As shown in the figure:\nThe program continues to run, assuming that the growth of generation 1 causes all its objects to occupy the full budget. At this time, the application allocates objects P to S, making the generation 0 objects reach their budget total. As shown in the figure:\nAt this time, the application is ready to allocate object T, since generation 1 is full, GC must start. But this time the garbage collector finds that generation 1 occupies too much memory, using up the budget. Since the previous GC on generation 0, there may already be many unreachable objects in generation 1. So this time the garbage collector decides to check all objects in generation 1 and generation 0. After garbage collection of both generations, the heap looks like the figure:\nThe managed heap only supports three generations: generation 0, generation 1, and generation 2.\nWhen CLR initializes, it selects a budget for each generation.\nHowever, CLR\u0026rsquo;s garbage collection is self-adjusting.\nThis means that the garbage collector learns about the program\u0026rsquo;s behavior during the garbage collection process.\nFor example: Assume that the application constructs many objects, but each object has a very short lifetime.\nIn this case, garbage collection of generation 0 will recycle a large amount of memory. In fact, all objects in generation 0 may be recycled.\nIf the garbage collector finds that after recycling generation 0, few objects survive, it may reduce the budget for generation 0. The reduction in allocated space means that garbage collection will occur more frequently, but the garbage collector does less each time, which reduces the process\u0026rsquo;s working set.\nOn the other hand, if the garbage collector recycles generation 0 and finds that many objects survive, little memory can be recycled, it will increase the budget for generation 0.\nThe same heuristic algorithm adjusts the budget for generation 1 and generation 2.\nQuoted from: \u0026ldquo;CLR VIA C# - Chapter 21\u0026rdquo;\nAutomatic Memory Management\nFundamentals of Garbage Collection\nGenerations\n","date":"2016-10-04T00:00:00Z","permalink":"https://liguobao.github.io/english/p/c%23.net-managed-heap-and-garbage-collection/","title":"C#.NET Managed Heap and Garbage Collection"},{"content":"Managed Heap and Garbage Collection (Continued) Large Objects CLR divides objects into large objects and small objects. Currently, objects of 85000 bytes or larger are considered large objects. CLR treats large objects differently.\nLarge objects are not allocated in the address space of small objects, but in other places in the process address space.\nThe current version of GC does not \u0026ldquo;compress\u0026rdquo; large objects because moving them in memory is too costly. But this may cause address space fragmentation between large objects in the process, leading to OutOfMemoryException. Future versions of CLR may compress large objects.\nLarge objects are always generation 2, never generation 0 or generation 1. So only create large objects for resources that need to live long. Allocating short-lived large objects will cause generation 2 to be recycled more frequently, losing performance. Large objects are generally large strings (XML/JSON) or byte arrays used for I/O operations (reading bytes from files/network into buffers for processing).\nGarbage Collection Modes When CLR starts, it selects a GC mode, and the mode in the process will not change before.\nThere are two basic GC modes.\nWorkstation This mode optimizes GC for client applications. The delay caused by GC is very low, and the application thread suspension time is short, avoiding user anxiety. In this mode, GC assumes that other applications running on the machine do not consume too much CPU resources. Server This mode optimizes GC for server applications. What is optimized is mainly throughput and resource utilization. GC assumes that no other applications are running on the machine (whether client or server applications), and assumes that all CPUs on the machine can be used to assist in completing GC. In this mode, the managed heap is split into several regions, one for each CPU. When starting garbage collection, the garbage collector runs a special thread on each CPU; each thread recycles its own region concurrently with other threads. For server applications where worker threads behave consistently, concurrent recycling can work well. This feature requires the application to run on a multi-CPU computer, so that threads can truly work simultaneously, thereby gaining performance improvement. Applications run in \u0026ldquo;workstation\u0026rdquo; GC mode by default. Server applications hosting CLR (such as ASP.NET) can request CLR to load server GC. But if the application runs on a single-processor computer, CLR always uses \u0026ldquo;workstation\u0026rdquo; GC mode.\nStandalone applications can create a configuration file to tell CLR to use the server recycler. The configuration file needs to add the gcServer element for the application. Below is an example configuration file:\n1 2 3 4 5 \u0026lt;configuration\u0026gt; \u0026lt;runtime\u0026gt; \u0026lt;gcServer enabled=\u0026#34;true\u0026#34;\u0026gt; \u0026lt;/runtime\u0026gt; \u0026lt;/configuration\u0026gt; You can use the read-only Boolean property IsServerGC of the GCSettings class to get whether CLR is in \u0026ldquo;server\u0026rdquo; GC mode.\nIn addition to these two modes, GC also supports two sub-modes: concurrent (default) or non-concurrent.\nIn concurrent mode, the garbage collector has an additional background thread that can mark objects concurrently while the application is running. While the program is running, the garbage collector runs a normal priority background thread to find unreachable objects. After finding them, the garbage collector suspends all threads again, determines whether to \u0026ldquo;compress\u0026rdquo; memory. If it decides to compress, memory is compressed, root references are corrected, and application threads resume running. This garbage collection takes less time than usual because the unreachable object collection has been constructed. But the garbage collector may also decide not to compress memory; in fact, the garbage collector tends not to compress. The more available memory, the less likely the garbage collector is to compress the heap; this helps enhance performance, but increases the program\u0026rsquo;s working set. Using concurrent garbage collector, applications usually consume more memory than using non-concurrent garbage collector.\n","date":"2016-10-04T00:00:00Z","permalink":"https://liguobao.github.io/english/p/c%23.net-managed-heap-and-garbage-collection-continued/","title":"C#.NET Managed Heap and Garbage Collection (Continued)"},{"content":"The CLR provides each AppDomain with a GC Handle Table that lets applications monitor or explicitly control object lifetimes. The table is empty when the AppDomain is created.\nEach entry contains:\nA reference to an object on the managed heap A flag describing how to monitor/control that object You typically interact with this via System.Runtime.InteropServices.GCHandle (e.g., GCHandleType.Weak, WeakTrackResurrection, Normal, Pinned). Use cases include pinning objects for interop or creating weak references without allocating WeakReference.\nExample (pinning):\n1 2 3 4 5 6 7 8 9 10 11 var bytes = new byte[1024]; var handle = GCHandle.Alloc(bytes, GCHandleType.Pinned); try { IntPtr ptr = handle.AddrOfPinnedObject(); // pass ptr to native API } finally { handle.Free(); } Example (weak):\n1 2 3 4 5 6 var target = new object(); var handle = GCHandle.Alloc(target, GCHandleType.Weak); target = null; GC.Collect(); var alive = handle.Target != null; // may be null after collection handle.Free(); Prefer high-level WeakReference unless you specifically need GCHandle semantics (e.g., pinning or resurrection tracking). Always Free() to avoid leaks.\n","date":"2016-10-04T00:00:00Z","permalink":"https://liguobao.github.io/english/p/clr-gc-handle-table-monitoring-and-controlling-object-lifetime/","title":"CLR GC Handle Table — Monitoring and Controlling Object Lifetime"},{"content":" Download mysql-connector-net installation mysql-connector-net\nAfter mysql-connector-net installation is complete, go to the corresponding installation directory and copy the corresponding MySQL .NET dll to CodeSmith\u0026rsquo;s bin directory and SchemaProviders directory. The general DLL directory is:\nC:\\Program Files (x86)\\MySQL\\MySQL Connector Net 6.9.8\\Assemblies\\v4.0\nRestart CodeSmith to take effect Other solutions: Solution for codesmith unable to connect to Mysql\nSolution for codesmith6.5 connecting to Mysql prompting \u0026ldquo;Cannot find the requested .Net Framework Data Provider. It may not be installed.\u0026rdquo;\n","date":"2016-10-04T00:00:00Z","permalink":"https://liguobao.github.io/english/p/codesmith-connect-mysql-database-error-cant-find-.net-framework-data-provider/","title":"CodeSmith Connect MySQL Database Error \"Can't Find .NET Framework Data Provider\""},{"content":"CodeSmith is a capable code generator on .NET. I used to target SQL Server with a set of templates for Model/DAL/BLL. After switching to MySQL, I found fewer resources, so I adapted templates and noted the process here.\nWorkflow: copy the template folder into CodeSmith’s template path, open CodeSmith, right‑click Main.cst → Execute → select the MySQL connection → choose tables → Generate.\nProblem: the original Main.cst used SchemaExplorer.TableSchema so you could only pick a single table. Solution: change it to SchemaExplorer.TableSchemaCollection and loop.\nSnippet:\n1 2 3 4 5 6 7 8 9 10 \u0026lt;%@ Property Name=\u0026#34;SourceTables\u0026#34; Type=\u0026#34;SchemaExplorer.TableSchemaCollection\u0026#34; %\u0026gt; \u0026lt;%@ Register Name=\u0026#34;SE\u0026#34; Template=\u0026#34;CreatSingleTable.cst\u0026#34; %\u0026gt; \u0026lt;% foreach(TableSchema ts in SourceTables) { SE s = new SE(); s.SourceTable = ts; s.RootNamespace = RootNamespace; s.OutputDirectory = OutputDirectory; s.Render(this.Response); } %\u0026gt; This generates Model/DAL/BLL for all selected tables in one go.\nField comments: the default MySQL provider SchemaExplorer.MySQLSchemaProvider.dll doesn’t populate column.Description. Replace the provider with a patched version to read column comments:\nHow‑to (Chinese): http://www.cnblogs.com/LonelyShadow/p/4147743.html\nTemplate repo: https://github.com/liguobao/CodeSmith-for-MySQL-Template\nNotes:\nThe template trims the first three chars of table names (prefix like tbl_ recommended), or adjust the template. Backup and replace SchemaExplorer.MySQLSchemaProvider.dll to enable column comments. ","date":"2016-10-04T00:00:00Z","permalink":"https://liguobao.github.io/english/p/codesmith-templates-for-mysql-multi-table-generation/","title":"CodeSmith Templates for MySQL — Multi-Table Generation"},{"content":"Battery usage report (Windows) Source: Microsoft Answers — Battery report / history\nOpen the taskbar search box, search for “PowerShell”. Right‑click “Windows PowerShell” → Run as administrator. Run this one‑liner to generate a localized HTML battery report on Desktop:\n1 $HTML=[System.Environment]::GetFolderPath(\u0026#39;Desktop\u0026#39;)+\u0026#34;\\\u0026#34;+(Get-Date -Format \u0026#39;yyyy-MM-dd\u0026#39;)+\u0026#34;-电池记录.html\u0026#34;;POWERCFG /BATTERYREPORT /OUTPUT \u0026#34;$HTML\u0026#34;;$TF=Get-Content \u0026#34;$HTML\u0026#34;;$TF| %{$_.Replace(\u0026#34;Battery report\u0026#34;,\u0026#34;电池报告\u0026#34;)}| %{$_.Replace(\u0026#34;COMPUTER NAME\u0026#34;,\u0026#34;计算机名\u0026#34;)}| %{$_.Replace(\u0026#34;SYSTEM PRODUCT NAME\u0026#34;,\u0026#34;计算机型号\u0026#34;)}| %{$_.Replace(\u0026#34;OS BUILD\u0026#34;,\u0026#34;操作系统内部版本\u0026#34;)}| %{$_.Replace(\u0026#34;PLATFORM ROLE\u0026#34;,\u0026#34;平台角色\u0026#34;)}| %{$_.Replace(\u0026#34;CONNECTED STANDBY\u0026#34;,\u0026#34;InstantGo（连接待机）\u0026#34;)}| %{$_.Replace(\u0026#34;REPORT TIME\u0026#34;,\u0026#34;报告时间\u0026#34;)}| %{$_.Replace(\u0026#34;Installed batteries\u0026#34;,\u0026#34;已安装的电池\u0026#34;)}| %{$_.Replace(\u0026#34;Information about each currently installed battery\u0026#34;,\u0026#34;查看当前已安装电池的信息\u0026#34;)}| %{$_.Replace(\u0026#34;NAME\u0026#34;,\u0026#34;名称\u0026#34;)}| %{$_.Replace(\u0026#34;MANUFACTURER\u0026#34;,\u0026#34;制造商\u0026#34;)}| %{$_.Replace(\u0026#34;SERIAL NUMBER\u0026#34;,\u0026#34;序列号\u0026#34;)}| %{$_.Replace(\u0026#34;CHEMISTRY\u0026#34;,\u0026#34;化学成分\u0026#34;)}| %{$_.Replace(\u0026#34;AT DESIGN CAPACITY\u0026#34;,\u0026#34;设计容量时\u0026#34;)}| %{$_.Replace(\u0026#34;DESIGN CAPACITY\u0026#34;,\u0026#34;设计容量\u0026#34;)}| %{$_.Replace(\u0026#34;FULL CHARGE CAPACITY\u0026#34;,\u0026#34;完全充电容量\u0026#34;)}| %{$_.Replace(\u0026#34;CYCLE COUNT\u0026#34;,\u0026#34;循环计数\u0026#34;)}| %{$_.Replace(\u0026#34;Recent usage\u0026#34;,\u0026#34;最近使用情况\u0026#34;)}| %{$_.Replace(\u0026#34;Power states over the last 3 days\u0026#34;,\u0026#34;过去72小时内的电源状态\u0026#34;)}| %{$_.Replace(\u0026#34;START TIME\u0026#34;,\u0026#34;开始时间\u0026#34;)}| %{$_.Replace(\u0026#34;STATE\u0026#34;,\u0026#34;状态\u0026#34;)}| %{$_.Replace(\u0026#34;SOURCE\u0026#34;,\u0026#34;电源\u0026#34;)}| %{$_.Replace(\u0026#34;CAPACITY REMAINING\u0026#34;,\u0026#34;剩余容量\u0026#34;)}| %{$_.Replace(\u0026#34;Battery usage\u0026#34;,\u0026#34;电池使用情况\u0026#34;)}| %{$_.Replace(\u0026#34;Battery drains over the last 3 days\u0026#34;,\u0026#34;过去72小时内的电池消耗\u0026#34;)}| %{$_.Replace(\u0026#34;DURATION\u0026#34;,\u0026#34;使用时间\u0026#34;)}| %{$_.Replace(\u0026#34;ENERGY DRAINED\u0026#34;,\u0026#34;消耗的能量\u0026#34;)}| %{$_.Replace(\u0026#34;Usage history\u0026#34;,\u0026#34;使用历史记录\u0026#34;)}| %{$_.Replace(\u0026#34;History of system usage on AC and battery\u0026#34;,\u0026#34;有关交流电源和电池的使用记录\u0026#34;)}| %{$_.Replace(\u0026#34;BATTERY DURATION\u0026#34;,\u0026#34;电池使用时间\u0026#34;)}| %{$_.Replace(\u0026#34;AC DURATION \u0026#34;,\u0026#34;交流电源使用时间\u0026#34;)}| %{$_.Replace(\u0026#34;PERIOD\u0026#34;,\u0026#34;周期\u0026#34;)}| %{$_.Replace(\u0026#34;ACTIVE\u0026#34;,\u0026#34;活动\u0026#34;)}| %{$_.Replace(\u0026#34;Battery capacity history\u0026#34;,\u0026#34;电池设计容量历史记录\u0026#34;)}| %{$_.Replace(\u0026#34;Charge capacity history of the system\u0026#39;s batteries\u0026#34;,\u0026#34;电池充电能力历史记录\u0026#34;)}| %{$_.Replace(\u0026#34;Battery life estimates based on observed drains\u0026#34;,\u0026#34;以观察到的消耗情况预计电池寿命\u0026#34;)}| %{$_.Replace(\u0026#34;Battery life estimates\u0026#34;,\u0026#34;预计电池寿命\u0026#34;)}| %{$_.Replace(\u0026#34;AT FULL CHARGE\u0026#34;,\u0026#34;完全充电时\u0026#34;)}| %{$_.Replace(\u0026#34;Current estimate of battery life based on all observed drains since OS install\u0026#34;,\u0026#34;以操作系统安装后所有观察到的消耗记录为基础预计的当前电池寿命\u0026#34;)}| %{$_.Replace(\u0026#34;Since OS install\u0026#34;,\u0026#34;从操作系统安装后\u0026#34;)}| %{$_.Replace(\u0026#34;Supported\u0026#34;,\u0026#34;支持\u0026#34;)}| %{$_.Replace(\u0026#34;Not supported\u0026#34;,\u0026#34;不支持\u0026#34;)}| %{$_.Replace(\u0026#34;BATTERY\u0026#34;,\u0026#34;电池\u0026#34;)}| %{$_.Replace(\u0026#34;Suspended\u0026#34;,\u0026#34;已暂停\u0026#34;)}| %{$_.Replace(\u0026#34;Active\u0026#34;,\u0026#34;活动\u0026#34;)}| %{$_.Replace(\u0026#34;Unspecified\u0026#34;,\u0026#34;未知\u0026#34;)}| %{$_.Replace(\u0026#34;Mobile\u0026#34;,\u0026#34;移动\u0026#34;)}| %{$_.Replace(\u0026#34;Desktop\u0026#34;,\u0026#34;桌面\u0026#34;)}| %{$_.Replace(\u0026#34;Workstation\u0026#34;,\u0026#34;工作站\u0026#34;)}| %{$_.Replace(\u0026#34;Report generated\u0026#34;,\u0026#34;生成当前报告\u0026#34;)}| %{$_.Replace(\u0026#34;Battery\u0026#34;,\u0026#34;电池\u0026#34;)}| %{$_.Replace(\u0026#34;AC\u0026#34;,\u0026#34;交流电源\u0026#34;)}|Out-File \u0026#34;$HTML\u0026#34;;pause ","date":"2016-10-04T00:00:00Z","permalink":"https://liguobao.github.io/english/p/handy-scripts-collection/","title":"Handy Scripts Collection"},{"content":"As we all know, when HTTPS pages request HTTP resources, modern browsers will intercept, prompt the user whether to continue, or directly intercept without prompting.\nRecently, I made a quick bookmark tool for myself. Clicking the bookmark directly sends the bookmark to the server address and saves it to my website.\nAt first, everything was normal, but when I encountered HTTPS websites, it crashed.\nAt first, I saw that HTTPS certificates are charged, so I thought forget it, as long as it works. A few days ago, I occasionally saw an open source software for free HTTPS application, and it looked good. These days I had time and started working on it. Below is a tutorial, and I applied for the certificate almost according to this.\nGet Free Certificate with Let\u0026rsquo;s Encrypt\nAbout this Let\u0026rsquo;s Encrypt, Wikipedia introduces it like this:\nLet\u0026rsquo;s Encrypt is a digital certificate certification authority that will be launched at the end of 2015, which will provide free SSL/TLS certificates for secure websites through an automated process designed to eliminate the complexity of manually creating and installing certificates. Let\u0026rsquo;s Encrypt is a service provided by the Internet Security Research Group (ISRG, a public welfare organization). Major sponsors include the Electronic Frontier Foundation, Mozilla Foundation, Akamai, and Cisco. On April 9, 2015, ISRG and the Linux Foundation announced cooperation to implement the protocol for this new digital certificate certification authority called Automatic Certificate Management Environment (ACME). There is a draft of this specification on GitHub, and a version of the proposal has been published as an Internet draft. Let\u0026rsquo;s Encrypt claims that this process will be very simple, automated, and free. On August 7, 2015, the service updated its launch plan, expecting to release the first certificate on September 7, 2015, and then issue a small number of certificates to whitelisted domains and gradually expand. If everything goes as planned, the service is expected to fully start providing on November 16, 2015.\nThe entire project has code on Github, mainly through the client to generate https certificates for our website.\nFirst, we download the client, as follows:\n1 git clone https://github.com/letsencrypt/letsencrypt.git Then enter this repository and execute the following code:\n1 ./letsencrypt-auto certonly -a webroot --webroot-path website path (such as: /var/www/web/) -d your domain (such as: test.online) -d www.your domain (such as: www.test.online) Here, note that I added line breaks for typesetting here, remember to remove the line breaks when running this command.\nLine breaks are in front of webroot and -d.\nIf everything goes well, we can see four files in the /etc/letsencrypt/live/domain/ directory, namely:\nDomain certificate file\nCertificate chain file that issued the domain certificate\nDomain certificate + certificate chain file\nPrivate key file\nAs shown in the figure:\nThen set the certificate for the website.\nJexus setting HTTPS requires changing the jws.conf document and the website configuration document.\nOperation steps are as follows:\nModify jws.conf Enter the Jexus folder, open \u0026ldquo;jws.conf\u0026rdquo;, add the following two sentences:\n1 2 CertificateFile = /etc/letsencrypt/live/domain/fullchain.pem CertificateKeyFile = /etc/letsencrypt/live/domain/privkey.pem The effect after modification is as follows:\nEnable HTTPS for the website Enter the siteconf/ folder, find the corresponding website conf file,\nChange the website service port to 443:\nport=443\nEnable https:\nUseHttps=true\nThe effect after modification is as follows:\nThen restart jexus.\nAfter completion, you can access through HTTPS.\nFinally, upload a picture of the HTTPS certificate to prove that this is feasible.\nSprinkle flowers, see you next time.\n","date":"2016-10-04T00:00:00Z","permalink":"https://liguobao.github.io/english/p/jexus-supports-https-protocol/","title":"Jexus Supports HTTPS Protocol"},{"content":"Cause: TLS/SSL configuration and cert chain issues under Mono. Fixes include enabling proper TLS versions and trusting root CAs.\n","date":"2016-10-04T00:00:00Z","permalink":"https://liguobao.github.io/english/p/mono-webrequest-https-exception-fix/","title":"Mono WebRequest HTTPS Exception — Fix"},{"content":"Chat Logs with My Grandparents Part 1 — On Landlords\nMe: It probably wasn’t them. In village XX (near my hometown) there was a landlord family. A classmate of mine is the great‑grandson; his grandfather (surname Deng) passed away when I was in high school. His grandma was the daughter of a landlord from another place. Deng Mingguang? Is that the person who owned the small three‑story cement house (whitewashed) in XX from the Republic era?\nGrandpa: That would be Deng Mingguang’s son, right?\nGrandma: It’s noon now — people are probably not around. (She chimed in; I don’t recall why.)\n…\nPart 2 — Fishing Nets\nMe: Grandpa, how did you make fishing nets back then?\nGrandpa: Hm?\nMe: The nets you used for fishing — how were they made?\n… (Original Chinese continues with daily life details; translated summary retained.)\n","date":"2015-08-31T00:00:00Z","permalink":"https://liguobao.github.io/english/p/chat-logs-with-my-grandparents/","title":"Chat Logs with My Grandparents"}]