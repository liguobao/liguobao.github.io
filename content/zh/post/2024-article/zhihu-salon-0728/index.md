---
title: 知乎盐沙龙-20240728
description: salon,知乎,2024
slug: zhihu-salon-0728
date: 2024-07-28 08:00:00+0000
categories:
  - Zhihu
tags:
  - zhihu
  - 2024
---

## 社区整体策略

- 回答为主

以运营团队为核心，产研驱动。

创作者为中心，创作为王。

知乎为深度内容社区。

## 产研驱动有什么

- 居委会、答主为业主

### 推荐算法升级

- 冷启动优化
- 算法目的调整
- 社区治理（引战、对立、内容管控；大概2%评论直接被清理。）
- 生态结构、鼓励专业垂直

以前，流量为王，PV、UV 为核心指标。

当前，深度内容、互动为重要指标。

### 热榜体验优化

- 降低引战、对立
- 内容运营策略调整
- 产品体验：取消折叠、新增精选
- 问题页排序：低质打压、TPR优化


#### True Positive Rate

```txt
TPR排序，全称为"True Positive Rate"排序，是一种在数据科学和机器学习领域常用的性能评估方式，尤其在处理分类任务时。"True Positive Rate"（真正例率），也被称为敏感度（Sensitivity）或召回率（Recall），是用于衡量模型正确识别正类的能力。

在分类任务中，将数据集分为正类（我们感充趣的类）和负类。对于一个给定的分类模型：
- 真正例（True Positive, TP）的数量是模型正确预测为正类的样本数量。
- 假正例（False Positive, FP）的数量是模型错误预测为正类的样本数量（实际上是负类）。
- 真负例（True Negative, TN）的数量是模型正确预测为负类的样本数量。
- 假负例（False Negative, FN）的数量是模型错误预测为负类的样本数量（实际上是正类）。

True Positive Rate（TPR）的计算方法如下：

\[ TPR = \frac{TP}{TP + FN} \]

这个比例反映了所有实际正类样本中，被模型正确识别出来的比例。TPR越高，表示模型对正类的识别能力越强。

TPR排序实际上是根据不同配置、阈值或模型下的TPR值来进行排序，从而评估和选择最优的模型或设置。在某些应用场景，如疾病筛查或欺诈检测中，高TPR尤为重要，因为我们希望尽可能多地识别出所有可能的正类（如病例或欺诈行为），即使这意味着会有更多的假正例（FP）。

综上，TPR排序是一种以模型或方法的真正例率作为标准进行比较和排序的方法，广泛应用于模型选择和性能比较中。
```

### 用户沟通机制

- 反馈

### AI内容的态度

- 观点提取、相似度、质量、可信度
- 抄袭识别与打击
- 反爬虫（SEO屏蔽了？）
- AIGC、Spam 识别

-> 限制分发、对于恶意账号处置

AI自己的“AI直答”呢？引用了谁的内容做了什么回答？给了

## For 作者体验

### 好问题

- 提问被弱化了
- 重复问题呢？刷问题的呢？（我能看到部分用户几千个提问和编辑问题）。这块的反作弊呢？

### 消息提醒优化

### 专栏

- 升级、曝光、增加流通、支持付费
- 知乎日报呢？
- SEO很高，内容质量很高（什么时候能重新开放？）


### 知乎直答-AI搜索

- ?